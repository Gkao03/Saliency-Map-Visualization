{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vivek_Training_PASCAL2012.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzRWJ57SX38g",
        "outputId": "d3222e62-9211-494d-fd7f-a9baa969cae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May  4 08:10:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_iwqplMXLu3",
        "outputId": "f20951d4-c608-4f25-ff4e-f178e8d5a0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "images currently in gdrive are faulty. copy original_data.zip to disk"
      ],
      "metadata": {
        "id": "6V5OU7rc1bv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls \"/content/gdrive/MyDrive/VL&R Project/data/PASCAL2012/Annotations/trainval\" -1 | wc -l"
      ],
      "metadata": {
        "id": "wvgIcDhSY8W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitely want to copy images to local folder so image fetching is faster"
      ],
      "metadata": {
        "id": "IerJwgUMdUD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/gdrive/MyDrive/VL&R Project/data/PASCAL2012/original_data.zip\" /content/"
      ],
      "metadata": {
        "id": "0lcXSBcm1BQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip original_data.zip"
      ],
      "metadata": {
        "id": "nQnMc-eY1MYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/__MACOSX/original_data/ /content/original_data"
      ],
      "metadata": {
        "id": "QoPiarVsaCqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/__MACOSX"
      ],
      "metadata": {
        "id": "qSrnEIsaaOla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/original_data/JPEGImages/trainval\" -1 | wc -l\n",
        "!ls \"/content/original_data/JPEGImages/test\" -1 | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QqYdNSbaWww",
        "outputId": "fb9bbf45-b9fe-43ad-ae19-91e81ae867ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16227\n",
            "898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy augmented images to disk"
      ],
      "metadata": {
        "id": "Jw3cCVSRGV0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELgjiOgeGrFQ",
        "outputId": "c81adc62-a532-41be-d407-a66ef0bb1e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rySzvwQYGtI7",
        "outputId": "c205eea7-732b-48f1-bcf1-abb1a89bfb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\toriginal_data  original_data.zip  sample_data  vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/gdrive/MyDrive/VL&R Project/data/PASCAL2012/FasterRCNN-Augmented.zip\" /content/"
      ],
      "metadata": {
        "id": "MUM9VCrAGX2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip FasterRCNN-Augmented.zip"
      ],
      "metadata": {
        "id": "es1TSzvxGhYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make sure ann and images have same count"
      ],
      "metadata": {
        "id": "mQSy01WY1jYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/FasterRCNN-Augmented/Annotations/trainval\" -1 | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSY1VJ7j1lmp",
        "outputId": "42adce28-227a-4ee7-e5ff-cafd1fde317f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/FasterRCNN-Augmented/JPEGImages/trainval\" -1 | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9huWyPb1n9Y",
        "outputId": "c19b63f5-3b32-448e-b9ed-67b184b84bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test an xml file"
      ],
      "metadata": {
        "id": "UPRNVJ1NaTCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xml_path = \"/content/gdrive/MyDrive/VL&R Project/data/PASCAL2012/Annotations/trainval/2007_000033.xml\""
      ],
      "metadata": {
        "id": "j8mR7nriZr8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xml_path = \"/content/original_data/Annotations/trainval/2007_000033.xml\""
      ],
      "metadata": {
        "id": "dwjE_ypybKb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists(xml_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gol0UKyvbWGG",
        "outputId": "df915057-aab3-42ed-afaf-e51b19841b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "tree = ET.parse(xml_path)\n",
        "root = tree.getroot()\n",
        "\n",
        "# size = root.findall(\"size\")\n",
        "\n",
        "# for s in size:\n",
        "#     width = s.findall(\"width\")[0].text\n",
        "#     print(width)\n",
        "\n",
        "b = []\n",
        "\n",
        "for child in root:\n",
        "    for t in child:\n",
        "        if t.tag == 'bndbox':\n",
        "            xmin = float(t.findall(\"xmin\")[0].text)\n",
        "            ymin = float(t.findall(\"ymin\")[0].text)\n",
        "            xmax = float(t.findall(\"xmax\")[0].text)\n",
        "            ymax = float(t.findall(\"ymax\")[0].text)\n",
        "            print(xmin, ymin, xmax, ymax)\n",
        "            assert xmin < xmax, f\"xmin not less than xmax\"\n",
        "            assert ymin < ymax, f\"ymin not less than ymax\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0vE1-RKazFy",
        "outputId": "6f262bc0-04a5-4827-819a-e7f2ec3f1df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.0 107.0 499.0 263.0\n",
            "421.0 200.0 482.0 226.0\n",
            "325.0 188.0 411.0 223.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# check trainval.txt to see if names are consistent with annotations or images. If not, just use names under annotations xor images folder (just a sanity check)"
      ],
      "metadata": {
        "id": "NxY5cdR0dIk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_path = \"/content/original_data/Indexes/trainval.txt\""
      ],
      "metadata": {
        "id": "DIYEI_w7-ra-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(index_path, 'r') as fp:\n",
        "    lines = fp.readlines()\n",
        "\n",
        "print(len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fHO5EbMA-no",
        "outputId": "de574490-f0a9-48fe-fe47-3b0cb897ad1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check all indices are present as images"
      ],
      "metadata": {
        "id": "yr1BjFPiE5bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann_dir = \"/content/original_data/Annotations/trainval\"\n",
        "img_dir = \"/content/original_data/JPEGImages/trainval\""
      ],
      "metadata": {
        "id": "nFuxGrDOE_aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_file = os.path.join(\"/content/original_data\", 'Indexes', 'trainval.txt')\n",
        "with open(split_file) as fp:\n",
        "    index_list = [line.strip() for line in fp]"
      ],
      "metadata": {
        "id": "gymanmm8QN_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in index_list:\n",
        "    pth = os.path.join(img_dir, line + \".jpg\")\n",
        "    assert(os.path.exists(pth))  # should not throw any assertion errors"
      ],
      "metadata": {
        "id": "3y0CeaTMEBjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Custom Dataset (Pascal2012)"
      ],
      "metadata": {
        "id": "0gY2u8qAJ8lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "bF9KbkCNKKp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import scipy.io\n",
        "import pickle\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8NlwP61qJ-SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math, torch, torchvision\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image, ImageEnhance, ImageOps\n",
        "\n",
        "def solarize_add(img, addition, threshold):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    added_img = img + addition\n",
        "    added_img = torch.clamp(added_img, 0, 255)\n",
        "    return F.to_pil_image(torch.where(img < threshold, added_img, img))\n",
        "\n",
        "\n",
        "def color(img, magnitude):\n",
        "    return ImageEnhance.Color(img).enhance(magnitude)\n",
        "\n",
        "\n",
        "def contrast(img, magnitude):\n",
        "    return ImageEnhance.Contrast(img).enhance(magnitude)\n",
        "\n",
        "\n",
        "def brightness(img, magnitude):\n",
        "    return ImageEnhance.Brightness(img).enhance(magnitude)\n",
        "\n",
        "\n",
        "def sharpness(img, magnitude):\n",
        "    return ImageEnhance.Sharpness(img).enhance(magnitude)\n",
        "\n",
        "\n",
        "def cutout(img, pad_size, replace):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    _, h, w = img.shape\n",
        "    center_h, center_w = torch.randint(high=h, size=(1,)), torch.randint(high=w, size=(1,))\n",
        "    low_h, high_h = torch.clamp(center_h-pad_size, 0, h), torch.clamp(center_h+pad_size, 0, h)\n",
        "    low_w, high_w = torch.clamp(center_w-pad_size, 0, w), torch.clamp(center_w+pad_size, 0, w)\n",
        "    cutout_img = img.clone()\n",
        "    cutout_img[:, low_h:high_h, low_w:high_w] = replace\n",
        "    return F.to_pil_image(cutout_img)\n",
        "\n",
        "\n",
        "def bbox_cutout(img, bboxs, pad_fraction, replace_with_mean):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    _, h, w = img.shape\n",
        "    random_index = torch.randint(len(bboxs), size=(1,))\n",
        "    chosen_bbox = bboxs[random_index]\n",
        "    min_x, min_y, max_x, max_y = chosen_bbox\n",
        "    min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "    \n",
        "    if (min_x == max_x) or (min_y == max_y): return F.to_pil_image(img)\n",
        "    \n",
        "    mask_x, mask_y = torch.randint(low=min_x, high=max_x, size=(1,)), torch.randint(low=min_y, high=max_y, size=(1,))\n",
        "    mask_w, mask_h = pad_fraction * w / 2, pad_fraction * h / 2\n",
        "    \n",
        "    x_min, x_max = int(torch.clamp(mask_x-mask_w, 0, w)), int(torch.clamp(mask_x+mask_w, 0, w))\n",
        "    y_min, y_max = int(torch.clamp(mask_y-mask_h, 0, h)), int(torch.clamp(mask_y+mask_h, 0, h))\n",
        "    \n",
        "    if replace_with_mean == True: replace = torch.mean(img[:, min_y:max_y, min_x:max_x])\n",
        "    else: replace = 128\n",
        "    \n",
        "    cutout_img = img.clone()\n",
        "    cutout_img[:, y_min:y_max, x_min:x_max] = replace\n",
        "    return F.to_pil_image(cutout_img)\n",
        "\n",
        "\n",
        "def _rotate_bbox(img, bboxs, degrees):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    _, h, w = img.shape\n",
        "    \n",
        "    rotate_bboxs = []\n",
        "    rotate_matrix = torch.FloatTensor([[math.cos(degrees*math.pi/180), math.sin(degrees*math.pi/180)], \n",
        "                                       [-math.sin(degrees*math.pi/180), math.cos(degrees*math.pi/180)]])\n",
        "    for bbox in bboxs:\n",
        "        min_x, min_y, max_x, max_y = bbox\n",
        "        rel_min_x, rel_max_x, rel_min_y, rel_max_y = min_x-w/2, max_x-w/2, min_y-h/2, max_y-h/2\n",
        "        coords = torch.FloatTensor([[rel_min_x, rel_min_y], \n",
        "                                    [rel_min_x, rel_max_y], \n",
        "                                    [rel_max_x, rel_max_y], \n",
        "                                    [rel_max_x, rel_min_y]])\n",
        "        rotate_coords = torch.matmul(rotate_matrix, coords.t()).t()\n",
        "        x_min, y_min = torch.min(rotate_coords, dim=0)[0]\n",
        "        x_max, y_max = torch.max(rotate_coords, dim=0)[0]\n",
        "        \n",
        "        rotate_min_x, rotate_max_x = torch.clamp(x_min+w/2, 0, w),torch.clamp(x_max+w/2, 0, w)\n",
        "        rotate_min_y, rotate_max_y = torch.clamp(y_min+h/2, 0, h),torch.clamp(y_max+h/2, 0, h)\n",
        "        rotate_bboxs.append(torch.FloatTensor([rotate_min_x, rotate_min_y, rotate_max_x, rotate_max_y]))\n",
        "    return torch.stack(rotate_bboxs)\n",
        "\n",
        "\n",
        "def translate_bbox(img, bboxs, pixels, replace, shift_horizontal):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    _, h, w = img.shape\n",
        "    \n",
        "    translate_bboxs = []\n",
        "    if shift_horizontal:\n",
        "        for bbox in bboxs:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            translate_min_x, translate_max_x = torch.clamp(min_x+pixels, 0, w), torch.clamp(max_x+pixels, 0, w)\n",
        "            translate_min_x, translate_max_x = int(translate_min_x), int(translate_max_x)\n",
        "            translate_bboxs.append(torch.FloatTensor([translate_min_x, min_y, translate_max_x, max_y]))\n",
        "    else:\n",
        "        for bbox in bboxs:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            translate_min_y, translate_max_y = torch.clamp(min_y+pixels, 0, h), torch.clamp(max_y+pixels, 0, h)\n",
        "            translate_min_y, translate_max_y = int(translate_min_y), int(translate_max_y)\n",
        "            translate_bboxs.append(torch.FloatTensor([min_x, translate_min_y, max_x, translate_max_y]))\n",
        "    return torch.stack(translate_bboxs)\n",
        "\n",
        "\n",
        "def shear_with_bboxes(img, bboxs, level, replace, shift_horizontal):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    _, h, w = img.shape\n",
        "    \n",
        "    shear_bboxs = []\n",
        "    if shift_horizontal:\n",
        "        shear_matrix = torch.FloatTensor([[1, -level], \n",
        "                                          [0, 1]])\n",
        "        for bbox in bboxs:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            coords = torch.FloatTensor([[min_x, min_y], \n",
        "                                        [min_x, max_y], \n",
        "                                        [max_x, max_y], \n",
        "                                        [max_x, min_y]])\n",
        "            shear_coords = torch.matmul(shear_matrix, coords.t()).t()\n",
        "            x_min, y_min = torch.min(shear_coords, dim=0)[0]\n",
        "            x_max, y_max = torch.max(shear_coords, dim=0)[0]\n",
        "            shear_min_x, shear_max_x = torch.clamp(x_min, 0, w), torch.clamp(x_max, 0, w)\n",
        "            shear_min_y, shear_max_y = torch.clamp(y_min, 0, h), torch.clamp(y_max, 0, h)\n",
        "            shear_bboxs.append(torch.FloatTensor([shear_min_x, shear_min_y, shear_max_x, shear_max_y]))\n",
        "    else:\n",
        "        shear_matrix = torch.FloatTensor([[1, 0], \n",
        "                                          [-level, 1]])\n",
        "        for bbox in bboxs:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            coords = torch.FloatTensor([[min_x, min_y], \n",
        "                                        [min_x, max_y], \n",
        "                                        [max_x, max_y], \n",
        "                                        [max_x, min_y]])\n",
        "            shear_coords = torch.matmul(shear_matrix, coords.t()).t()\n",
        "            x_min, y_min = torch.min(shear_coords, dim=0)[0]\n",
        "            x_max, y_max = torch.max(shear_coords, dim=0)[0]\n",
        "            shear_min_x, shear_max_x = torch.clamp(x_min, 0, w), torch.clamp(x_max, 0, w)\n",
        "            shear_min_y, shear_max_y = torch.clamp(y_min, 0, h), torch.clamp(y_max, 0, h)\n",
        "            shear_bboxs.append(torch.FloatTensor([shear_min_x, shear_min_y, shear_max_x, shear_max_y]))\n",
        "    return torch.stack(shear_bboxs)\n",
        "\n",
        "\n",
        "def rotate_only_bboxes(img, bboxs, p, degrees, replace):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    rotate_img = torch.zeros_like(img)\n",
        "\n",
        "    for bbox in bboxs:\n",
        "        if torch.rand(1) < p:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "            bbox_rotate_img = F.to_pil_image(img[:, min_y:max_y+1, min_x:max_x+1]).rotate(degrees, fillcolor=(replace,replace,replace))\n",
        "            rotate_img[:, min_y:max_y+1, min_x:max_x+1] = F.pil_to_tensor(bbox_rotate_img)\n",
        "    return F.to_pil_image(torch.where(rotate_img != 0, rotate_img, img))\n",
        "\n",
        "\n",
        "def shear_only_bboxes(img, bboxs, p, level, replace, shift_horizontal):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    shear_img = torch.zeros_like(img)\n",
        "    \n",
        "    for bbox in bboxs:\n",
        "        if torch.rand(1) < p:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "            \n",
        "            bbox_shear_img = F.to_pil_image(img[:, min_y:max_y+1, min_x:max_x+1])\n",
        "            if shift_horizontal:\n",
        "                bbox_shear_img = bbox_shear_img.transform(bbox_shear_img.size, Image.AFFINE, (1,level,0,0,1,0), fillcolor=(replace,replace,replace))\n",
        "            else:\n",
        "                bbox_shear_img = bbox_shear_img.transform(bbox_shear_img.size, Image.AFFINE, (1,0,0,level,1,0), fillcolor=(replace,replace,replace))\n",
        "            shear_img[:, min_y:max_y+1, min_x:max_x+1] = F.pil_to_tensor(bbox_shear_img)\n",
        "\n",
        "    return F.to_pil_image(torch.where(shear_img != 0, shear_img, img))\n",
        "\n",
        "\n",
        "def translate_only_bboxes(img, bboxs, p, pixels, replace, shift_horizontal):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    translate_img = torch.zeros_like(img)\n",
        "    \n",
        "    for bbox in bboxs:\n",
        "        if torch.rand(1) < p:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "            \n",
        "            bbox_tran_img = F.to_pil_image(img[:, min_y:max_y+1, min_x:max_x+1])\n",
        "            if shift_horizontal:\n",
        "                bbox_tran_img = bbox_tran_img.transform(bbox_tran_img.size, Image.AFFINE, (1,0,-pixels,0,1,0), fillcolor=(replace,replace,replace))\n",
        "            else:\n",
        "                bbox_tran_img = bbox_tran_img.transform(bbox_tran_img.size, Image.AFFINE, (1,0,0,0,1,-pixels), fillcolor=(replace,replace,replace))\n",
        "            translate_img[:, min_y:max_y+1, min_x:max_x+1] = F.pil_to_tensor(bbox_tran_img)\n",
        "    \n",
        "    return F.to_pil_image(torch.where(translate_img != 0, translate_img, img))\n",
        "\n",
        "\n",
        "def flip_only_bboxes(img, bboxs, p):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    flip_img = torch.zeros_like(img)\n",
        "    \n",
        "    for bbox in bboxs:\n",
        "        if torch.rand(1) < p:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "            flip_img[:, min_y:max_y+1, min_x:max_x+1] = F.hflip(img[:, min_y:max_y+1, min_x:max_x+1])\n",
        "    \n",
        "    return F.to_pil_image(torch.where(flip_img != 0, flip_img, img))\n",
        "\n",
        "\n",
        "def solarize_only_bboxes(img, bboxs, p, threshold):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    for bbox in bboxs:\n",
        "        if torch.rand(1) < p:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "            solarize_img = img[:, min_y:max_y+1, min_x:max_x+1]\n",
        "            solarize_img = F.to_pil_image(solarize_img)\n",
        "            solarize_img = ImageOps.solarize(solarize_img, threshold=threshold)\n",
        "            solarize_img = F.pil_to_tensor(solarize_img)\n",
        "            img[:, min_y:max_y+1, min_x:max_x+1] = solarize_img\n",
        "    return F.to_pil_image(img)\n",
        "\n",
        "\n",
        "def equalize_only_bboxes(img, bboxs, p):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    for bbox in bboxs:\n",
        "        if torch.rand(1) < p:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "            equalize_img = img[:, min_y:max_y+1, min_x:max_x+1]\n",
        "            equalize_img = F.to_pil_image(equalize_img)\n",
        "            equalize_img = ImageOps.equalize(equalize_img)\n",
        "            equalize_img = F.pil_to_tensor(equalize_img)\n",
        "            img[:, min_y:max_y+1, min_x:max_x+1] = equalize_img\n",
        "    return F.to_pil_image(img)\n",
        "\n",
        "\n",
        "def cutout_only_bboxes(img, bboxs, p, pad_size, replace):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    cutout_img = img.clone()\n",
        "    \n",
        "    for bbox in bboxs:\n",
        "        if torch.rand(1) < p:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
        "            \n",
        "            cutout_x, cutout_y = torch.randint(low=min_x, high=max_x, size=(1,)), torch.randint(low=min_y, high=max_y, size=(1,))\n",
        "            \n",
        "            y_min, y_max = int(torch.clamp(cutout_y-pad_size, min_y, max_y)), int(torch.clamp(cutout_y+pad_size, min_y, max_y))\n",
        "            x_min, x_max = int(torch.clamp(cutout_x-pad_size, min_x, max_x)), int(torch.clamp(cutout_x+pad_size, min_x, max_x))\n",
        "            \n",
        "            cutout_img[:, y_min:y_max, x_min:x_max] = replace\n",
        "\n",
        "    return F.to_pil_image(cutout_img)\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "\n",
        "### Basic Augmentation\n",
        "class Compose:\n",
        "    \"\"\"\n",
        "    Composes several transforms together.\n",
        "    \"\"\"\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, bboxs):\n",
        "        for t in self.transforms:\n",
        "            image, bboxs = t(image, bboxs)\n",
        "        return image, bboxs\n",
        "\n",
        "\n",
        "class ToTensor:\n",
        "    \"\"\"\n",
        "    Converts a PIL Image or numpy.ndarray (H x W x C) to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __call__(self, image, bboxs):\n",
        "        return F.to_tensor(image), bboxs\n",
        "\n",
        "\n",
        "class Normalize(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Normalize a tensor image with mean and standard deviation.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, mean, std, inplace=False):\n",
        "        super().__init__()\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        return F.normalize(image, self.mean, self.std, self.inplace), bboxs\n",
        "\n",
        "\n",
        "### Coior Augmentation\n",
        "class AutoContrast(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Autocontrast the pixels of the given image.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "      try:\n",
        "        image = ImageOps.invert(image.convert('RGB'))\n",
        "        autocontrast_image = ImageOps.autocontrast(image)\n",
        "      except:\n",
        "        autocontrast_image = image\n",
        "        # if torch.rand(1) < self.p:\n",
        "        #     autocontrast_image = ImageOps.autocontrast(image)\n",
        "        #     return autocontrast_image, bboxs\n",
        "        # else:\n",
        "      return autocontrast_image, bboxs\n",
        "\n",
        "\n",
        "class Brightness(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Adjust image brightness using magnitude.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, magnitude, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.magnitude = magnitude\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.magnitude *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            brightness_image = brightness(image, 1+self.magnitude)\n",
        "            return brightness_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class Color(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Adjust image color balance using magnitude.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, magnitude, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.magnitude = magnitude\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.magnitude *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            color_image = color(image, 1+self.magnitude)\n",
        "            return color_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class Contrast(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Adjust image contrast using magnitude.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, magnitude, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.magnitude = magnitude\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.magnitude *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            contrast_image = contrast(image, 1+self.magnitude)\n",
        "            return contrast_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class Equalize(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Equalize the histogram of the given image.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if torch.rand(1) < self.p:\n",
        "            equalize_image = ImageOps.equalize(image)\n",
        "            return equalize_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class Posterize(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Posterize the image by reducing the number of bits for each color channel.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, bits):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.bits = int(bits)\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if torch.rand(1) < self.p:\n",
        "            image = ImageOps.invert(image.convert('RGB'))\n",
        "            posterize_image = ImageOps.posterize(image, self.bits)\n",
        "            return posterize_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class Sharpness(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Adjust image sharpness using magnitude.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, magnitude, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.magnitude = magnitude\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.magnitude *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            sharpness_image = sharpness(image, 1+self.magnitude)\n",
        "            return sharpness_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class Solarize(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Solarize the image by inverting all pixel values above a threshold.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, threshold):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.threshold = int(threshold)\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if torch.rand(1) < self.p:\n",
        "            solarize_image = ImageOps.solarize(image, self.threshold)\n",
        "            return solarize_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class SolarizeAdd(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Solarize the image by added image below a threshold.\n",
        "    Add addition amount to image and then clip the pixel value to 0~255 or 0~1.\n",
        "    Parameter addition must be integer.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, addition, threshold=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.addition = int(addition)\n",
        "        self.threshold = int(threshold)\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.addition *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            solarize_add_image = solarize_add(image, self.addition, self.threshold)\n",
        "            return solarize_add_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "### Geometric Augmentation\n",
        "class Rotate_BBox(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Rotate image by degrees and change bboxes according to rotated image.\n",
        "    The pixel values filled in will be of the value replace.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Both applied to image and bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, degrees, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.degrees = degrees\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.degrees *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            rotate_image = image.rotate(self.degrees, fillcolor=(self.replace, self.replace, self.replace))\n",
        "            if bboxs == None:\n",
        "                return rotate_image, bboxs\n",
        "            else:\n",
        "                rotate_bbox = _rotate_bbox(image, bboxs, self.degrees)\n",
        "                return rotate_image, rotate_bbox\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class ShearX_BBox(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Shear image and change bboxes on X-axis.\n",
        "    The pixel values filled in will be of the value replace.\n",
        "    Level is usually between -0.3~0.3.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Both applied to image and bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, level, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.level = level\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.level *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            shear_image = image.transform(image.size, Image.AFFINE, (1, self.level, 0, 0, 1, 0), fillcolor=(self.replace, self.replace, self.replace))\n",
        "            if bboxs == None:\n",
        "                return shear_image, bboxs\n",
        "            else:\n",
        "                shear_bbox = shear_with_bboxes(image, bboxs, self.level, self.replace, shift_horizontal=True)\n",
        "                return shear_image, shear_bbox\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class ShearY_BBox(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Shear image and change bboxes on Y-axis.\n",
        "    The pixel values filled in will be of the value replace.\n",
        "    Level is usually between -0.3~0.3.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Both applied to image and bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, level, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.level = level\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.level *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            shear_image = image.transform(image.size, Image.AFFINE, (1, 0, 0, self.level, 1, 0), fillcolor=(self.replace, self.replace, self.replace))\n",
        "            if bboxs == None:\n",
        "                return shear_image, bboxs\n",
        "            else:\n",
        "                shear_bbox = shear_with_bboxes(image, bboxs, self.level, self.replace, shift_horizontal=False)\n",
        "                return shear_image, shear_bbox\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "def translate_bbbox(img, bboxs, pixels, replace, shift_horizontal):\n",
        "    img = F.pil_to_tensor(img)\n",
        "    _, h, w = img.shape\n",
        "    \n",
        "    translate_bboxs = []\n",
        "    if shift_horizontal:\n",
        "        for bbox in bboxs:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            translate_min_x, translate_max_x = np.clip(min_x+pixels, 0, w), np.clip(max_x+pixels, 0, w)\n",
        "            translate_min_x, translate_max_x = int(translate_min_x), int(translate_max_x)\n",
        "            translate_bboxs.append(torch.FloatTensor([translate_min_x, min_y, translate_max_x, max_y]))\n",
        "    else:\n",
        "        for bbox in bboxs:\n",
        "            min_x, min_y, max_x, max_y = bbox\n",
        "            translate_min_y, translate_max_y = np.clip(min_y+pixels, 0, h), np.clip(max_y+pixels, 0, h)\n",
        "            translate_min_y, translate_max_y = int(translate_min_y), int(translate_max_y)\n",
        "            translate_bboxs.append(torch.FloatTensor([min_x, translate_min_y, max_x, translate_max_y]))\n",
        "    return torch.stack(translate_bboxs)\n",
        "\n",
        "class TranslateX_BBox(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Translate image and bboxes on X-axis.\n",
        "    The pixel values filled in will be of the value replace.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Both applied to image and bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, pixels, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.pixels = int(pixels)\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.pixels *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            translate_image = image.transform(image.size, Image.AFFINE, (1, 0, -self.pixels, 0, 1, 0), fillcolor=(self.replace, self.replace, self.replace))\n",
        "            if bboxs == None:\n",
        "                return translate_image, bboxs\n",
        "            else:\n",
        "                translate_bbox = translate_bbbox(image, bboxs, self.pixels, self.replace, shift_horizontal=True)\n",
        "                return translate_image, translate_bbox\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class TranslateY_BBox(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Translate image and bboxes on Y-axis.\n",
        "    The pixel values filled in will be of the value replace.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Both applied to image and bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, pixels, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.pixels = int(pixels)\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.pixels *= -1\n",
        "        if torch.rand(1) < self.p:\n",
        "            translate_image = image.transform(image.size, Image.AFFINE, (1, 0, 0, 0, 1, -self.pixels), fillcolor=(self.replace, self.replace, self.replace))\n",
        "            if bboxs == None:\n",
        "                return translate_image, bboxs\n",
        "            else:\n",
        "                translate_bbox = translate_bbbox(image, bboxs, self.pixels, self.replace, shift_horizontal=False)\n",
        "                return translate_image, translate_bbox\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "### Mask Augmentation\n",
        "class Cutout(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply cutout (https://arxiv.org/abs/1708.04552) to the image.\n",
        "    This operation applies a (2*pad_size, 2*pad_size) mask of zeros to a random location within image.\n",
        "    The pixel values filled in will be of the value replace.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, pad_size, replace=128):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.pad_size = int(pad_size)\n",
        "        self.replace = replace\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if torch.rand(1) < self.p:\n",
        "            cutout_image = cutout(image, self.pad_size, self.replace)\n",
        "            return cutout_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "### Color Augmentation based on BBoxes\n",
        "class Equalize_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply equalize to each bboxes in the image with probability.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            equalize_image = equalize_only_bboxes(image, bboxs, self.p)\n",
        "            return equalize_image, bboxs\n",
        "\n",
        "\n",
        "class Solarize_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply solarize to each bboxes in the image with probability.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, threshold):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "        self.threshold = int(threshold)\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            solarize_image = solarize_only_bboxes(image, bboxs, self.p, self.threshold)\n",
        "            return solarize_image, bboxs\n",
        "\n",
        "\n",
        "### Geometric Augmentation based on BBoxes\n",
        "class Rotate_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply rotation to each bboxes in the image with probability.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, degrees, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "        self.degrees = degrees\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.degrees *= -1\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            rotate_image = rotate_only_bboxes(image, bboxs, self.p, self.degrees, self.replace)\n",
        "            return rotate_image, bboxs\n",
        "\n",
        "\n",
        "class ShearX_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply shear to each bboxes in the image with probability only on X-axis.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, level, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "        self.level = level\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.level *= -1\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            shear_image = shear_only_bboxes(image, bboxs, self.p, self.level, self.replace, shift_horizontal=True)\n",
        "            return shear_image, bboxs\n",
        "\n",
        "\n",
        "class ShearY_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply shear to each bboxes in the image with probability only on Y-axis.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, level, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "        self.level = level\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.level *= -1\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            shear_image = shear_only_bboxes(image, bboxs, self.p, self.level, self.replace, shift_horizontal=False)\n",
        "            return shear_image, bboxs\n",
        "\n",
        "\n",
        "class TranslateX_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply translation to each bboxes in the image with probability only on X-axis.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, pixels, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "        self.pixels = int(pixels)\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.pixels *= -1\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            translate_image = translate_only_bboxes(image, bboxs, self.p, self.pixels, self.replace, shift_horizontal=True)\n",
        "            return translate_image, bboxs\n",
        "\n",
        "\n",
        "class TranslateY_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply transloation to each bboxes in the image with probability only on Y-axis.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, pixels, replace=128, minus=True):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "        self.pixels = int(pixels)\n",
        "        self.replace = replace\n",
        "        self.minus = minus\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if self.minus and (torch.rand(1) < 0.5): self.pixels *= -1\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            translate_image = translate_only_bboxes(image, bboxs, self.p, self.pixels, self.replace, shift_horizontal=False)\n",
        "            return translate_image, bboxs\n",
        "\n",
        "\n",
        "class Flip_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply horizontal flip to each bboxes in the image with probability.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            flip_image = flip_only_bboxes(image, bboxs, self.p)\n",
        "            return flip_image, bboxs\n",
        "\n",
        "\n",
        "### Mask Augmentation based on BBoxes\n",
        "class BBox_Cutout(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply cutout to the image according to bbox information.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image, not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, pad_fraction, replace_with_mean=False):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.pad_fraction = pad_fraction\n",
        "        self.replace_with_mean = replace_with_mean\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if (torch.rand(1) < self.p) and (bboxs != None):\n",
        "            cutout_image = bbox_cutout(image, bboxs, self.pad_fraction, self.replace_with_mean)\n",
        "            return cutout_image, bboxs\n",
        "        else:\n",
        "            return image, bboxs\n",
        "\n",
        "\n",
        "class Cutout_Only_BBoxes(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Apply cutout to each bboxes in the image with probability.\n",
        "    Assume the coords are given min_x, min_y, max_x, max_y.\n",
        "    Only applied to image not bboxes.\n",
        "    \"\"\"\n",
        "    def __init__(self, p, pad_size, replace=128):\n",
        "        super().__init__()\n",
        "        self.p = p/3\n",
        "        self.pad_size = int(pad_size)\n",
        "        self.replace = replace\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        if bboxs == None:\n",
        "            return image, bboxs\n",
        "        else:\n",
        "            cutout_image = cutout_only_bboxes(image, bboxs, self.p, self.pad_size, self.replace)\n",
        "            return cutout_image, bboxs\n",
        "\n",
        "\n",
        "import torch, random\n",
        "\n",
        "M = 10\n",
        "\n",
        "color_range = torch.arange(0, 0.9+1e-8, (0.9-0)/M).tolist()\n",
        "rotate_range = torch.arange(0, 30+1e-8, (30-0)/M).tolist()\n",
        "shear_range = torch.arange(0, 0.3+1e-8, (0.3-0)/M).tolist()\n",
        "translate_range = torch.arange(0, 250+1e-8, (250-0)/M).tolist()\n",
        "translate_bbox_range = torch.arange(0, 120+1e-8, (120-0)/M).tolist()\n",
        "\n",
        "\n",
        "Mag = {'Brightness' : color_range, 'Color' : color_range, 'Contrast' : color_range, \n",
        "       'Posterize' : torch.arange(4, 8+1e-8, (8-4)/M).tolist()[::-1], 'Sharpness' : color_range, \n",
        "       'Solarize' : torch.arange(0, 256+1e-8, (256-0)/M).tolist()[::-1], 'SolarizeAdd' : torch.arange(0, 110+1e-8, (110-0)/M).tolist(),\n",
        "       \n",
        "       'Cutout' : torch.arange(0, 100+1e-8, (100-0)/M).tolist(),\n",
        "       \n",
        "       'Rotate_BBox' : rotate_range, 'ShearX_BBox' : shear_range, 'ShearY_BBox' : shear_range,\n",
        "       'TranslateX_BBox' : translate_range, 'TranslateY_BBox' : translate_range,\n",
        "           \n",
        "       'Rotate_Only_BBoxes' : rotate_range, 'ShearX_Only_BBoxes' : shear_range, 'ShearY_Only_BBoxes' : shear_range,\n",
        "       'TranslateX_Only_BBoxes' : translate_bbox_range, 'TranslateY_Only_BBoxes' : translate_bbox_range,\n",
        "       \n",
        "       'Solarize_Only_BBoxes' : torch.arange(0, 256+1e-8, (256-0)/M).tolist()[::-1],\n",
        "       \n",
        "       'BBox_Cutout' : torch.arange(0, 0.75+1e-8, (0.75-0)/M).tolist(), 'Cutout_Only_BBoxes' : torch.arange(0, 50+1e-8, (50-0)/M).tolist()\n",
        "      }\n",
        "\n",
        "\n",
        "Fun = {'AutoContrast' : AutoContrast, 'Brightness' : Brightness, 'Color' : Color, 'Contrast' : Contrast, 'Equalize' : Equalize, \n",
        "       'Posterize' : Posterize, 'Sharpness' : Sharpness, 'Solarize' : Solarize, 'SolarizeAdd' : SolarizeAdd,\n",
        "       \n",
        "       'Cutout' : Cutout,\n",
        "       \n",
        "       'Rotate_BBox' : Rotate_BBox, 'ShearX_BBox' : ShearX_BBox, 'ShearY_BBox' : ShearY_BBox,\n",
        "       'TranslateX_BBox' : TranslateX_BBox, 'TranslateY_BBox' : TranslateY_BBox,\n",
        "           \n",
        "       'Rotate_Only_BBoxes' : Rotate_Only_BBoxes, 'ShearX_Only_BBoxes' : ShearX_Only_BBoxes, 'ShearY_Only_BBoxes' : ShearY_Only_BBoxes,\n",
        "       'TranslateX_Only_BBoxes' : TranslateX_Only_BBoxes, 'TranslateY_Only_BBoxes' : TranslateY_Only_BBoxes, 'Flip_Only_BBoxes' : Flip_Only_BBoxes,\n",
        "       \n",
        "       'Equalize_Only_BBoxes' : Equalize_Only_BBoxes, 'Solarize_Only_BBoxes' : Solarize_Only_BBoxes,\n",
        "       \n",
        "       'BBox_Cutout' : BBox_Cutout, 'Cutout_Only_BBoxes' : Cutout_Only_BBoxes\n",
        "      }\n",
        "\n",
        "\n",
        "class Policy(torch.nn.Module):\n",
        "    def __init__(self, policy, pre_transform, post_transform):\n",
        "        super().__init__()\n",
        "        self.pre_transform = pre_transform\n",
        "        self.post_transform = post_transform\n",
        "        \n",
        "        if policy == 'policy_v0': self.policy = policy_v0()\n",
        "        elif policy == 'policy_v1': self.policy = policy_v1()\n",
        "        elif policy == 'policy_v2': self.policy = policy_v2()\n",
        "        elif policy == 'policy_v3': self.policy = policy_v3()\n",
        "        elif policy == 'policy_vtest': self.policy = policy_vtest()\n",
        "\n",
        "    def forward(self, image, bboxs):\n",
        "        policy_idx = random.randint(0, len(self.policy)-1)\n",
        "        policy_transform = self.pre_transform + self.policy[policy_idx] + self.post_transform\n",
        "        policy_transform = Compose(policy_transform)\n",
        "        image, bboxs = policy_transform(image, bboxs)\n",
        "        return image, bboxs\n",
        "    \n",
        "    \n",
        "def SubPolicy(f1, p1, m1, f2, p2, m2):\n",
        "    subpolicy = []\n",
        "    if f1 in ['AutoContrast', 'Equalize', 'Equalize_Only_BBoxes', 'Flip_Only_BBoxes']: subpolicy.append(Fun[f1](p1))\n",
        "    else: subpolicy.append(Fun[f1](p1, Mag[f1][m1]))\n",
        "    \n",
        "    if f2 in ['AutoContrast', 'Equalize', 'Equalize_Only_BBoxes', 'Flip_Only_BBoxes']: subpolicy.append(Fun[f2](p2))\n",
        "    else: subpolicy.append(Fun[f2](p2, Mag[f2][m2]))\n",
        "        \n",
        "    return subpolicy\n",
        "\n",
        "\n",
        "def SubPolicy3(f1, p1, m1, f2, p2, m2, f3, p3, m3):\n",
        "    subpolicy = []\n",
        "    if f1 in ['AutoContrast', 'Equalize', 'Equalize_Only_BBoxes', 'Flip_Only_BBoxes']: subpolicy.append(Fun[f1](p1))\n",
        "    else: subpolicy.append(Fun[f1](p1, Mag[f1][m1]))\n",
        "    \n",
        "    if f2 in ['AutoContrast', 'Equalize', 'Equalize_Only_BBoxes', 'Flip_Only_BBoxes']: subpolicy.append(Fun[f2](p2))\n",
        "    else: subpolicy.append(Fun[f2](p2, Mag[f2][m2]))\n",
        "        \n",
        "    if f3 in ['AutoContrast', 'Equalize', 'Equalize_Only_BBoxes', 'Flip_Only_BBoxes']: subpolicy.append(Fun[f3](p3))\n",
        "    else: subpolicy.append(Fun[f3](p3, Mag[f3][m3]))\n",
        "        \n",
        "    return subpolicy  \n",
        "    \n",
        "\n",
        "def policy_v0():\n",
        "    policy = [SubPolicy('TranslateX_BBox', 0.6, 4,           'Equalize', 0.8, None),\n",
        "              SubPolicy('TranslateY_Only_BBoxes', 0.2, 2,    'Cutout', 0.8, 8),\n",
        "              SubPolicy('Sharpness', 0.0, 8,                 'ShearX_BBox', 0.4, 0),\n",
        "              SubPolicy('ShearY_BBox', 1.0, 2,               'TranslateY_Only_BBoxes', 0.6, 6),\n",
        "              SubPolicy('Rotate_BBox', 0.6, 10,              'Color', 1.0, 6)]\n",
        "    return policy\n",
        "\n",
        "\n",
        "def policy_v1():\n",
        "    policy = [SubPolicy('TranslateX_BBox', 0.6, 4,           'Equalize', 0.8, None),\n",
        "              SubPolicy('TranslateY_Only_BBoxes', 0.2, 2,    'Cutout', 0.8, 8),\n",
        "              SubPolicy('Sharpness', 0, 8,                   'ShearX_BBox', 0.4, 0),\n",
        "              SubPolicy('ShearY_BBox', 1.0, 2,               'TranslateY_Only_BBoxes', 0.6, 6),\n",
        "              SubPolicy('Rotate_BBox', 0.6, 10,              'Color', 1.0, 6),\n",
        "              SubPolicy('Color', 0.0, 0,                     'ShearX_Only_BBoxes', 0.8, 4),\n",
        "              SubPolicy('ShearY_Only_BBoxes', 0.8, 2,        'Flip_Only_BBoxes', 0.0, None),\n",
        "              SubPolicy('Equalize', 0.6, None,               'TranslateX_BBox', 0.2, 2),\n",
        "              SubPolicy('Color', 1.0, 10,                    'TranslateY_Only_BBoxes', 0.4, 6),\n",
        "              SubPolicy('Rotate_BBox', 0.8, 10,              'Contrast', 0.0, 10),\n",
        "              SubPolicy('Cutout', 0.2, 2,                    'Brightness', 0.8, 10),\n",
        "              SubPolicy('Color', 1.0, 6,                     'Equalize', 1.0, None),\n",
        "              SubPolicy('Cutout_Only_BBoxes', 0.4, 6,        'TranslateY_Only_BBoxes', 0.8, 2),\n",
        "              SubPolicy('Color', 0.2, 8,                     'Rotate_BBox', 0.8, 10),\n",
        "              SubPolicy('Sharpness', 0.4, 4,                 'TranslateY_Only_BBoxes', 0.0, 4),\n",
        "              SubPolicy('Sharpness', 1.0, 4,                 'SolarizeAdd', 0.4, 4),\n",
        "              SubPolicy('Rotate_BBox', 1.0, 8,               'Sharpness', 0.2, 8),\n",
        "              SubPolicy('ShearY_BBox', 0.6, 10,              'Equalize_Only_BBoxes', 0.6, None),\n",
        "              SubPolicy('ShearX_BBox', 0.2, 6,               'TranslateY_Only_BBoxes', 0.2, 10),\n",
        "              SubPolicy('SolarizeAdd', 0.6, 8,               'Brightness', 0.8, 10)]\n",
        "    return policy\n",
        "\n",
        "\n",
        "def policy_vtest():\n",
        "    policy = [SubPolicy('TranslateX_BBox', 1.0, 4,           'Equalize', 1.0, None)]\n",
        "    return policy\n",
        "\n",
        "\n",
        "def policy_v2():\n",
        "    policy = [SubPolicy3('Color', 0.0, 6,                    'Cutout', 0.6, 8,                 'Sharpness', 0.4, 8),\n",
        "              SubPolicy3('Rotate_BBox', 0.4, 8,              'Sharpness', 0.4, 2,              'Rotate_BBox', 0.8, 10),\n",
        "              SubPolicy('TranslateY_BBox', 1.0, 8,           'AutoContrast', 0.8, None),\n",
        "              SubPolicy3('AutoContrast', 0.4, None,          'ShearX_BBox', 0.8, 8,            'Brightness', 0.0, 10),\n",
        "              SubPolicy3('SolarizeAdd', 0.2, 6,              'Contrast', 0.0, 10,              'AutoContrast', 0.6, None),\n",
        "              SubPolicy3('Cutout', 0.2, 0,                   'Solarize', 0.8, 8,               'Color', 1.0, 4),\n",
        "              SubPolicy3('TranslateY_BBox', 0.0, 4,          'Equalize', 0.6, None,            'Solarize', 0.0, 10),\n",
        "              SubPolicy3('TranslateY_BBox', 0.2, 2,          'ShearY_BBox', 0.8, 8,            'Rotate_BBox', 0.8, 8),\n",
        "              SubPolicy3('Cutout', 0.8, 8,                   'Brightness', 0.8, 8,             'Cutout', 0.2, 2),\n",
        "              SubPolicy3('Color', 0.8, 4,                    'TranslateY_BBox', 1.0, 6,        'Rotate_BBox', 0.6, 6),\n",
        "              SubPolicy3('Rotate_BBox', 0.6, 10,             'BBox_Cutout', 1.0, 4,            'Cutout', 0.2, 8),\n",
        "              SubPolicy3('Rotate_BBox', 0.0, 0,              'Equalize', 0.6, None,            'ShearY_BBox', 0.6, 8),\n",
        "              SubPolicy3('Brightness', 0.8, 8,               'AutoContrast', 0.4, None,        'Brightness', 0.2, 2),\n",
        "              SubPolicy3('TranslateY_BBox', 0.4, 8,          'Solarize', 0.4, 6,               'SolarizeAdd', 0.2, 10),\n",
        "              SubPolicy3('Contrast', 1.0, 10,                'SolarizeAdd', 0.2, 8,            'Equalize', 0.2, None)]\n",
        "    return policy\n",
        "\n",
        "              \n",
        "def policy_v3():\n",
        "    policy = [SubPolicy('Posterize', 0.8, 2,                 'TranslateX_BBox', 1.0, 8),\n",
        "              SubPolicy('BBox_Cutout', 0.2, 10,              'Sharpness', 1.0, 8),\n",
        "              SubPolicy('Rotate_BBox', 0.6, 8,               'Rotate_BBox', 0.8, 10),\n",
        "              SubPolicy('Equalize', 0.8, None,               'AutoContrast', 0.2, None),\n",
        "              SubPolicy('SolarizeAdd', 0.2, 2,               'TranslateY_BBox', 0.2, 8),\n",
        "              SubPolicy('Sharpness', 0.0, 2,                 'Color', 0.4, 8),\n",
        "              SubPolicy('Equalize', 1.0, None,               'TranslateY_BBox', 1.0, 8),\n",
        "              SubPolicy('Posterize', 0.6, 2,                 'Rotate_BBox', 0.0, 10),\n",
        "              SubPolicy('AutoContrast', 0.6, None,           'Rotate_BBox', 1.0, 6),\n",
        "              SubPolicy('Equalize', 0.0, None,               'Cutout', 0.8, 10),\n",
        "              SubPolicy('Brightness', 1.0, 2,                'TranslateY_BBox', 1.0, 6),\n",
        "              SubPolicy('Contrast', 0.0, 2,                  'ShearY_BBox', 0.8, 0),\n",
        "              SubPolicy('AutoContrast', 0.8, None,           'Contrast', 0.2, 10),\n",
        "              SubPolicy('Rotate_BBox', 1.0, 10,              'Cutout', 1.0, 10),\n",
        "              SubPolicy('SolarizeAdd', 0.8, 6,               'Equalize', 0.8, None)]\n",
        "    return policy"
      ],
      "metadata": {
        "id": "hkLksJdTdNR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the original COCO mapping with pretrained weights!\n",
        "coco_names = ['__background__', 'person', 'bicycle', 'car', 'motorbike', 'aeroplane', \\\n",
        "              'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', \n",
        "              'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', \n",
        "              'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella',\n",
        "              'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
        "              'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "              'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass', 'cup', 'fork',\n",
        "              'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
        "              'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "              'pottedplant', 'bed', 'N/A', 'diningtable', 'N/A', 'N/A', 'toilet',\n",
        "              'N/A', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
        "              'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock', 'vase',\n",
        "              'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "metadata": {
        "id": "jawIJKgz9uVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "# from torchvision.transforms import Compose, ToTensor\n",
        "import scipy.io\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class PASCALDataset(Dataset):\n",
        "    CLASS_NAMES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n",
        "                   'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
        "                   'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "    INV_CLASS = {}\n",
        "    \n",
        "    for i in range(len(CLASS_NAMES)):\n",
        "        INV_CLASS[CLASS_NAMES[i]] = i\n",
        "\n",
        "    CLASS_NAMES.insert(0, '__background__') # Adding background class with 0 index\n",
        "\n",
        "\n",
        "    def __init__(self, split='trainval', data_dir=\"/content/original_data\", save_lbl_pth='/content/gdrive/MyDrive/VL&R Project/data/PASCAL2012'):\n",
        "        super().__init__()\n",
        "        self.split      = split     # 'trainval' or 'test'\n",
        "        self.data_dir   = data_dir\n",
        "        self.label_pth = os.path.join(save_lbl_pth, split + \"_label.pkl\")\n",
        "        \n",
        "        self.img_dir = os.path.join(data_dir, 'JPEGImages', split)\n",
        "        self.ann_dir = os.path.join(data_dir, 'Annotations', split)\n",
        "\n",
        "        split_file = os.path.join(data_dir, 'Indexes', split + '.txt')\n",
        "        with open(split_file) as fp:\n",
        "            self.index_list = [line.strip() for line in fp]\n",
        "\n",
        "        self.anno_list = self.preload_anno()\n",
        "\n",
        "    @classmethod\n",
        "    def get_class_name(cls, index):\n",
        "        return cls.CLASS_NAMES[index]\n",
        "\n",
        "    @classmethod\n",
        "    def get_class_index(cls, name):\n",
        "        return cls.INV_CLASS[name]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index_list)\n",
        "\n",
        "    def preload_anno(self):\n",
        "        \"\"\"\n",
        "        :return: a list of labels. each element is in the form of [class, weight, gt_class_list, gt_boxes],\n",
        "         where both class and weight are arrays/tensors in shape of [20],\n",
        "         gt_class_list is a list of the class ids (separate for each instance)\n",
        "         gt_boxes is a list of [xmin, ymin, xmax, ymax] values in the range 0 to 1\n",
        "        \"\"\"        \n",
        "        if os.path.exists(self.label_pth):\n",
        "            print(f\"preloading from path {self.label_pth}\")\n",
        "            label_list = []\n",
        "            with open(self.label_pth, 'rb') as fp:\n",
        "                label_list = pickle.load(fp)\n",
        "            \n",
        "            return label_list\n",
        "\n",
        "        label_list = []\n",
        "        # print(f\"reading data to save to {self.label_pth}\")\n",
        "\n",
        "        for i, index in tqdm(enumerate(self.index_list)):\n",
        "            fpath = os.path.join(self.ann_dir, index + '.xml')\n",
        "            tree = ET.parse(fpath)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # print(f\"parsing {index}\")\n",
        "\n",
        "            C = np.zeros(20)\n",
        "            W = np.ones(20) * 2 # default to enable 1 or 0 later for difficulty\n",
        "\n",
        "            # new list for each index\n",
        "            gt_class_list = []\n",
        "            gt_boxes = []\n",
        "\n",
        "            for child in root:\n",
        "                \n",
        "                if child.tag == 'object':\n",
        "                    C[self.INV_CLASS[child[0].text]] = 1    # item at index of child name become 1\n",
        "                    if child[3].text == '1' and W[self.INV_CLASS[child[0].text]] == 2:\n",
        "                        W[self.INV_CLASS[child[0].text]] = 0    # if not difficult, weight is one\n",
        "                    elif child[3].text == '0' :\n",
        "                        W[self.INV_CLASS[child[0].text]] = 1\n",
        "                    \n",
        "                    # add class_index to gt_class_list\n",
        "                    gt_class_list.append(self.INV_CLASS[child[0].text])\n",
        "\n",
        "                    for t in child:\n",
        "                        if t.tag == 'bndbox':\n",
        "                            xmin = float(t.findall(\"xmin\")[0].text)\n",
        "                            ymin = float(t.findall(\"ymin\")[0].text)\n",
        "                            xmax = float(t.findall(\"xmax\")[0].text)\n",
        "                            ymax = float(t.findall(\"ymax\")[0].text)\n",
        "                            assert xmin < xmax, f\"xmin not less than xmax for {index}\"\n",
        "                            assert ymin < ymax, f\"ymin not less than ymax for {index}\"\n",
        "                            gt_boxes.append([xmin, ymin, xmax, ymax])\n",
        "                    \n",
        "            for i in range(len(W)):\n",
        "                if W[i] == 2:\n",
        "                    W[i] = 1\n",
        "\n",
        "            label_list.append([C, W, gt_class_list, gt_boxes])\n",
        "            \n",
        "        # uncomment if you want to save the pickled label list to preload next time\n",
        "        # with open(self.label_pth, 'wb') as fp:\n",
        "        #   pickle.dump(label_list, fp)\n",
        "\n",
        "        return label_list\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        :param index: a int generated by Dataloader in range [0, __len__()]\n",
        "        :return: index-th element - containing all the aforementioned information\n",
        "        \"\"\"\n",
        "        # The input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each image, and should be in 0-1 range.\n",
        "        # Different images can have different sizes but they will be resized to a fixed size before passing it to the backbone.\n",
        "        # During training, the model expects both the input tensors, as well as a targets (list of dictionary), containing:\n",
        "\n",
        "        # boxes (FloatTensor[N, 4]): the ground-truth boxes in [x1, y1, x2, y2] format, with 0 <= x1 < x2 <= W and 0 <= y1 < y2 <= H.\n",
        "\n",
        "        # labels (Int64Tensor[N]): the class label for each ground-truth box\n",
        "        findex = self.index_list[index]     # findex refers to the file number\n",
        "        fpath = os.path.join(self.img_dir, findex + '.jpg')\n",
        "\n",
        "        # image: a PIL Image of size (H, W)\n",
        "        img = Image.open(fpath).convert(\"RGB\")\n",
        "        img = transforms.ToTensor()(img)\n",
        "\n",
        "\n",
        "        '''\n",
        "        One note on the labels. The model considers class 0 as background.\n",
        "        If your dataset does not contain the background class, you should not have 0 in your labels.\n",
        "        For example, assuming you have just two classes, cat and dog, you can define 1 (not 0) to represent cats\n",
        "        and 2 to represent dogs. So, for instance, if one of the images has both classes, your labels tensor should look like [1,2].\n",
        "\n",
        "        Edit: So basically add 1 to all the label classes!\n",
        "        '''\n",
        "\n",
        "        \n",
        "        # first id is the background, so remove it =====> Verify this!\n",
        "        # obj_ids = obj_ids[1:]\n",
        "\n",
        "\n",
        "        # target: a dict containing the following fields\n",
        "\n",
        "        # 1. boxes (FloatTensor[N, 4]): the coordinates of the N bounding boxes in [x0, y0, x1, y1] format, ranging from 0 to W and 0 to H\n",
        "        labels, boxes = self.anno_list[index][2], self.anno_list[index][3]\n",
        "\n",
        "        aug_list = [Policy(policy='policy_v3',    pre_transform=[], post_transform=[])]\n",
        "\n",
        "        transform = T.ToPILImage()\n",
        "        img = transform(img)\n",
        "        aug_image, aug_bboxes = aug_list[0](img, boxes)\n",
        "        aug_image = transforms.ToTensor()(aug_image)\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "\n",
        "        # 2. labels (Int64Tensor[N]): the label for each bounding box. 0 represents always the background class.\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64) + 1 # Add 1 since background class has been added!\n",
        "\n",
        "\n",
        "        # 3. image_id (Int64Tensor[1]): an image identifier.\n",
        "        # It should be unique between all the images in the dataset, and is used during evaluation\n",
        "        image_id = torch.tensor([index])\n",
        "\n",
        "        # 4. area (Tensor[N]): The area of the bounding box.\n",
        "        # This is used during evaluation with the COCO metric, to separate the metric scores between small, medium and large boxes.\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        # 5. iscrowd (UInt8Tensor[N]): instances with iscrowd=True will be ignored during evaluation.\n",
        "        # Suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
        "\n",
        "\n",
        "        target = {}\n",
        "\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "        return aug_image, target"
      ],
      "metadata": {
        "id": "Y01YUF0gj3-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model (FASTER RCNN)"
      ],
      "metadata": {
        "id": "yyd7DyBwJ3Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "from tkinter import N\n",
        "import sklearn\n",
        "import sklearn.metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "M1-zVIBHJ-hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "iX1LRidAAWTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "# model = torchvision.models.detection.ssd300_vgg16(pretrained=False, num_classes=len(PASCALDataset.CLASS_NAMES) + 1)\n",
        "\n",
        "# load a model pre-trained on COCO\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# replace the classifier with a new one, that has\n",
        "# num_classes which is user-defined\n",
        "num_classes = len(PASCALDataset.CLASS_NAMES) + 1\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model.train().to(device)"
      ],
      "metadata": {
        "id": "gtfGuIUVMzH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for name, layer in model.named_modules():\n",
        "#     print(name, layer)"
      ],
      "metadata": {
        "id": "-fXtx10CpQCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## some more hyperparams"
      ],
      "metadata": {
        "id": "aOBar0SzS-Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.005\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "WrrO2qS3S_v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define optimizer, scheduler"
      ],
      "metadata": {
        "id": "_AG8ruW6ThEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1) # From the official docs"
      ],
      "metadata": {
        "id": "uzqCufNcJ4r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We'll need another library for this (using this library's train function)"
      ],
      "metadata": {
        "id": "7y1svtFOD2l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wN_9yzLcpG7",
        "outputId": "e3c80dbf-90db-4fe7-e7e2-1faa46ebfe32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coco_eval.py   engine.py\t\t presets.py   README.md  transforms.py\n",
            "coco_utils.py  group_by_aspect_ratio.py  __pycache__  train.py\t utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/vision.git"
      ],
      "metadata": {
        "id": "TYOUEqP1D2DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8trGo1qEKQ7",
        "outputId": "5b45bfbc-eccc-4b6d-fb07-35d94936c491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vision/references/detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.environ['PYTHONPATH'])\n",
        "os.environ['PYTHONPATH'] += \":\" + \"/content/vision/references/detection\"\n",
        "print(os.environ['PYTHONPATH'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6sDdPjMENk2",
        "outputId": "ae5de42d-b4ad-45a7-cbbc-f68d87b99d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python:/content/vision/references/detection:/content/vision/references/detection\n",
            "/env/python:/content/vision/references/detection:/content/vision/references/detection:/content/vision/references/detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/vision/references/detection\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETb8CkzZEyGf",
        "outputId": "7b9ad58a-2618-42d4-fa47-0c70d0233b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vision/references/detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Function"
      ],
      "metadata": {
        "id": "H-kwn2lTUnRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import functions from inside the /content/vision/references/detection path\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils"
      ],
      "metadata": {
        "id": "OUdqTUSYEcW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define dataset and dataloader"
      ],
      "metadata": {
        "id": "6BiW_utHWTtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We require utils for the collate function\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "batch_size = 4\n",
        "num_workers = 4\n",
        "\n",
        "\n",
        "train_dataset = PASCALDataset('trainval', data_dir=\"/content/original_data\")\n",
        "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=num_workers,pin_memory=True,collate_fn=utils.collate_fn)\n",
        "print('\\n', len(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA3CHA2YLJex",
        "outputId": "1b4d7659-3bf8-480b-de8b-f30c749e7e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16227it [00:01, 9879.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 4057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = PASCALDataset('test', data_dir=\"/content/original_data\")\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=num_workers,pin_memory=True,collate_fn=utils.collate_fn)\n",
        "print('\\n', len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnhDGrhuLq_F",
        "outputId": "6d8245cd-f85a-46e5-e548-b240c92a3242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "898it [00:00, 9148.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runner"
      ],
      "metadata": {
        "id": "P3Xqbo-JWN4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    # train for one epoch\n",
        "\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=100)\n",
        "\n",
        "    # VIVEK ADD EVALUATION Done! \\(^_^)/\n",
        "    evaluate(model, test_loader, device=device)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# save_path = os.path.join(\"/content/gdrive/MyDrive/VL&R Project/pascal-training/saved_models\", f\"faster-rcnn_epochs{epochs}.pt\")\n",
        "# torch.save(model, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSSdsOHaMTfC",
        "outputId": "7f6ac556-918c-4855-b0b9-1636cefdeeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [   0/4057]  eta: 1:27:07  lr: 0.000010  loss: 3.9357 (3.9357)  loss_classifier: 3.5577 (3.5577)  loss_box_reg: 0.3220 (0.3220)  loss_objectness: 0.0087 (0.0087)  loss_rpn_box_reg: 0.0472 (0.0472)  time: 1.2884  data: 0.4637  max mem: 10941\n",
            "Epoch: [0]  [ 100/4057]  eta: 0:44:50  lr: 0.000509  loss: 0.5594 (1.2817)  loss_classifier: 0.2877 (0.9726)  loss_box_reg: 0.2436 (0.2793)  loss_objectness: 0.0082 (0.0147)  loss_rpn_box_reg: 0.0110 (0.0152)  time: 0.6718  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [ 200/4057]  eta: 0:43:22  lr: 0.001009  loss: 0.4504 (0.9392)  loss_classifier: 0.2077 (0.6299)  loss_box_reg: 0.2419 (0.2790)  loss_objectness: 0.0055 (0.0147)  loss_rpn_box_reg: 0.0101 (0.0156)  time: 0.6744  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [ 300/4057]  eta: 0:41:54  lr: 0.001508  loss: 0.3714 (0.7775)  loss_classifier: 0.1835 (0.4896)  loss_box_reg: 0.1798 (0.2578)  loss_objectness: 0.0103 (0.0147)  loss_rpn_box_reg: 0.0098 (0.0153)  time: 0.6382  data: 0.0008  max mem: 10941\n",
            "Epoch: [0]  [ 400/4057]  eta: 0:41:02  lr: 0.002008  loss: 0.3274 (0.6793)  loss_classifier: 0.1403 (0.4099)  loss_box_reg: 0.1666 (0.2406)  loss_objectness: 0.0065 (0.0137)  loss_rpn_box_reg: 0.0157 (0.0151)  time: 0.6770  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [ 500/4057]  eta: 0:40:09  lr: 0.002507  loss: 0.3291 (0.6172)  loss_classifier: 0.1297 (0.3583)  loss_box_reg: 0.1715 (0.2295)  loss_objectness: 0.0055 (0.0140)  loss_rpn_box_reg: 0.0111 (0.0154)  time: 0.7247  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [ 600/4057]  eta: 0:39:09  lr: 0.003007  loss: 0.3107 (0.5731)  loss_classifier: 0.1366 (0.3221)  loss_box_reg: 0.1602 (0.2219)  loss_objectness: 0.0086 (0.0140)  loss_rpn_box_reg: 0.0102 (0.0152)  time: 0.6831  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [ 700/4057]  eta: 0:38:07  lr: 0.003506  loss: 0.2601 (0.5375)  loss_classifier: 0.1087 (0.2954)  loss_box_reg: 0.1253 (0.2127)  loss_objectness: 0.0087 (0.0139)  loss_rpn_box_reg: 0.0146 (0.0155)  time: 0.6769  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [ 800/4057]  eta: 0:37:06  lr: 0.004006  loss: 0.2850 (0.5094)  loss_classifier: 0.1261 (0.2749)  loss_box_reg: 0.1505 (0.2052)  loss_objectness: 0.0071 (0.0137)  loss_rpn_box_reg: 0.0097 (0.0155)  time: 0.6817  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [ 900/4057]  eta: 0:35:57  lr: 0.004505  loss: 0.2739 (0.4900)  loss_classifier: 0.1213 (0.2594)  loss_box_reg: 0.1286 (0.2014)  loss_objectness: 0.0109 (0.0135)  loss_rpn_box_reg: 0.0171 (0.0157)  time: 0.6446  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1000/4057]  eta: 0:34:50  lr: 0.005000  loss: 0.2831 (0.4706)  loss_classifier: 0.1255 (0.2456)  loss_box_reg: 0.1431 (0.1953)  loss_objectness: 0.0093 (0.0137)  loss_rpn_box_reg: 0.0129 (0.0159)  time: 0.6785  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1100/4057]  eta: 0:33:46  lr: 0.005000  loss: 0.3331 (0.4549)  loss_classifier: 0.1457 (0.2347)  loss_box_reg: 0.1766 (0.1907)  loss_objectness: 0.0097 (0.0134)  loss_rpn_box_reg: 0.0141 (0.0160)  time: 0.6886  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1200/4057]  eta: 0:32:41  lr: 0.005000  loss: 0.2489 (0.4402)  loss_classifier: 0.1022 (0.2251)  loss_box_reg: 0.1240 (0.1859)  loss_objectness: 0.0063 (0.0132)  loss_rpn_box_reg: 0.0143 (0.0160)  time: 0.7334  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [1300/4057]  eta: 0:31:35  lr: 0.005000  loss: 0.2410 (0.4298)  loss_classifier: 0.0917 (0.2173)  loss_box_reg: 0.1157 (0.1825)  loss_objectness: 0.0092 (0.0138)  loss_rpn_box_reg: 0.0092 (0.0162)  time: 0.6781  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1400/4057]  eta: 0:30:26  lr: 0.005000  loss: 0.2298 (0.4180)  loss_classifier: 0.1008 (0.2098)  loss_box_reg: 0.0923 (0.1783)  loss_objectness: 0.0082 (0.0137)  loss_rpn_box_reg: 0.0095 (0.0162)  time: 0.6548  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1500/4057]  eta: 0:29:18  lr: 0.005000  loss: 0.3334 (0.4108)  loss_classifier: 0.1319 (0.2048)  loss_box_reg: 0.1451 (0.1760)  loss_objectness: 0.0150 (0.0139)  loss_rpn_box_reg: 0.0138 (0.0162)  time: 0.6778  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [1600/4057]  eta: 0:28:09  lr: 0.005000  loss: 0.1982 (0.4021)  loss_classifier: 0.0902 (0.1991)  loss_box_reg: 0.1043 (0.1731)  loss_objectness: 0.0075 (0.0138)  loss_rpn_box_reg: 0.0096 (0.0162)  time: 0.6673  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1700/4057]  eta: 0:27:02  lr: 0.005000  loss: 0.2266 (0.3952)  loss_classifier: 0.0862 (0.1946)  loss_box_reg: 0.1108 (0.1707)  loss_objectness: 0.0049 (0.0137)  loss_rpn_box_reg: 0.0111 (0.0162)  time: 0.6995  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1800/4057]  eta: 0:25:53  lr: 0.005000  loss: 0.2536 (0.3874)  loss_classifier: 0.1006 (0.1897)  loss_box_reg: 0.1207 (0.1680)  loss_objectness: 0.0088 (0.0136)  loss_rpn_box_reg: 0.0121 (0.0161)  time: 0.6814  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [1900/4057]  eta: 0:24:45  lr: 0.005000  loss: 0.2377 (0.3815)  loss_classifier: 0.0980 (0.1862)  loss_box_reg: 0.1048 (0.1657)  loss_objectness: 0.0075 (0.0135)  loss_rpn_box_reg: 0.0144 (0.0161)  time: 0.6949  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [2000/4057]  eta: 0:23:37  lr: 0.005000  loss: 0.2603 (0.3764)  loss_classifier: 0.1032 (0.1830)  loss_box_reg: 0.1578 (0.1638)  loss_objectness: 0.0053 (0.0134)  loss_rpn_box_reg: 0.0137 (0.0162)  time: 0.6682  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [2100/4057]  eta: 0:22:28  lr: 0.005000  loss: 0.2213 (0.3713)  loss_classifier: 0.0901 (0.1796)  loss_box_reg: 0.1049 (0.1620)  loss_objectness: 0.0084 (0.0134)  loss_rpn_box_reg: 0.0151 (0.0162)  time: 0.7040  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [2200/4057]  eta: 0:21:18  lr: 0.005000  loss: 0.2257 (0.3672)  loss_classifier: 0.0865 (0.1768)  loss_box_reg: 0.1180 (0.1608)  loss_objectness: 0.0072 (0.0134)  loss_rpn_box_reg: 0.0157 (0.0161)  time: 0.6842  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [2300/4057]  eta: 0:20:10  lr: 0.005000  loss: 0.2353 (0.3626)  loss_classifier: 0.0953 (0.1741)  loss_box_reg: 0.1079 (0.1589)  loss_objectness: 0.0074 (0.0133)  loss_rpn_box_reg: 0.0114 (0.0162)  time: 0.6994  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [2400/4057]  eta: 0:19:01  lr: 0.005000  loss: 0.2859 (0.3587)  loss_classifier: 0.1287 (0.1716)  loss_box_reg: 0.1370 (0.1575)  loss_objectness: 0.0080 (0.0133)  loss_rpn_box_reg: 0.0155 (0.0162)  time: 0.6747  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [2500/4057]  eta: 0:17:51  lr: 0.005000  loss: 0.2181 (0.3555)  loss_classifier: 0.1032 (0.1696)  loss_box_reg: 0.0904 (0.1564)  loss_objectness: 0.0076 (0.0133)  loss_rpn_box_reg: 0.0117 (0.0162)  time: 0.7314  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [2600/4057]  eta: 0:16:42  lr: 0.005000  loss: 0.2302 (0.3523)  loss_classifier: 0.1199 (0.1676)  loss_box_reg: 0.1056 (0.1554)  loss_objectness: 0.0081 (0.0132)  loss_rpn_box_reg: 0.0091 (0.0162)  time: 0.7061  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [2700/4057]  eta: 0:15:34  lr: 0.005000  loss: 0.2018 (0.3483)  loss_classifier: 0.0939 (0.1654)  loss_box_reg: 0.0764 (0.1537)  loss_objectness: 0.0066 (0.0130)  loss_rpn_box_reg: 0.0103 (0.0161)  time: 0.7140  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [2800/4057]  eta: 0:14:25  lr: 0.005000  loss: 0.2267 (0.3449)  loss_classifier: 0.1011 (0.1634)  loss_box_reg: 0.1059 (0.1525)  loss_objectness: 0.0066 (0.0130)  loss_rpn_box_reg: 0.0098 (0.0161)  time: 0.6935  data: 0.0006  max mem: 10941\n",
            "Epoch: [0]  [2900/4057]  eta: 0:13:16  lr: 0.005000  loss: 0.2118 (0.3425)  loss_classifier: 0.1113 (0.1618)  loss_box_reg: 0.1026 (0.1515)  loss_objectness: 0.0081 (0.0131)  loss_rpn_box_reg: 0.0104 (0.0161)  time: 0.6721  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [3000/4057]  eta: 0:12:07  lr: 0.005000  loss: 0.1980 (0.3405)  loss_classifier: 0.0972 (0.1606)  loss_box_reg: 0.0996 (0.1508)  loss_objectness: 0.0065 (0.0130)  loss_rpn_box_reg: 0.0076 (0.0161)  time: 0.6953  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [3100/4057]  eta: 0:10:58  lr: 0.005000  loss: 0.2125 (0.3378)  loss_classifier: 0.0879 (0.1592)  loss_box_reg: 0.1203 (0.1498)  loss_objectness: 0.0054 (0.0129)  loss_rpn_box_reg: 0.0095 (0.0160)  time: 0.6954  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [3200/4057]  eta: 0:09:49  lr: 0.005000  loss: 0.2025 (0.3352)  loss_classifier: 0.0816 (0.1576)  loss_box_reg: 0.0884 (0.1488)  loss_objectness: 0.0068 (0.0128)  loss_rpn_box_reg: 0.0141 (0.0160)  time: 0.6996  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [3300/4057]  eta: 0:08:41  lr: 0.005000  loss: 0.2481 (0.3336)  loss_classifier: 0.1099 (0.1567)  loss_box_reg: 0.0932 (0.1482)  loss_objectness: 0.0093 (0.0127)  loss_rpn_box_reg: 0.0138 (0.0160)  time: 0.6955  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [3400/4057]  eta: 0:07:32  lr: 0.005000  loss: 0.2479 (0.3315)  loss_classifier: 0.1065 (0.1554)  loss_box_reg: 0.1194 (0.1474)  loss_objectness: 0.0065 (0.0127)  loss_rpn_box_reg: 0.0103 (0.0160)  time: 0.6939  data: 0.0006  max mem: 10941\n",
            "Epoch: [0]  [3500/4057]  eta: 0:06:23  lr: 0.005000  loss: 0.2105 (0.3292)  loss_classifier: 0.0958 (0.1542)  loss_box_reg: 0.0825 (0.1464)  loss_objectness: 0.0079 (0.0126)  loss_rpn_box_reg: 0.0129 (0.0160)  time: 0.6592  data: 0.0002  max mem: 10941\n",
            "Epoch: [0]  [3600/4057]  eta: 0:05:14  lr: 0.005000  loss: 0.2667 (0.3276)  loss_classifier: 0.1014 (0.1531)  loss_box_reg: 0.1178 (0.1458)  loss_objectness: 0.0093 (0.0127)  loss_rpn_box_reg: 0.0101 (0.0160)  time: 0.7104  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [3700/4057]  eta: 0:04:05  lr: 0.005000  loss: 0.2769 (0.3262)  loss_classifier: 0.1092 (0.1522)  loss_box_reg: 0.1201 (0.1452)  loss_objectness: 0.0110 (0.0127)  loss_rpn_box_reg: 0.0191 (0.0160)  time: 0.6719  data: 0.0004  max mem: 10941\n",
            "Epoch: [0]  [3800/4057]  eta: 0:02:56  lr: 0.005000  loss: 0.2107 (0.3245)  loss_classifier: 0.0840 (0.1511)  loss_box_reg: 0.1053 (0.1447)  loss_objectness: 0.0100 (0.0127)  loss_rpn_box_reg: 0.0116 (0.0160)  time: 0.7158  data: 0.0006  max mem: 10941\n",
            "Epoch: [0]  [3900/4057]  eta: 0:01:48  lr: 0.005000  loss: 0.3178 (0.3239)  loss_classifier: 0.1340 (0.1506)  loss_box_reg: 0.1448 (0.1445)  loss_objectness: 0.0085 (0.0127)  loss_rpn_box_reg: 0.0218 (0.0161)  time: 0.6930  data: 0.0003  max mem: 10941\n",
            "Epoch: [0]  [4000/4057]  eta: 0:00:39  lr: 0.005000  loss: 0.2088 (0.3227)  loss_classifier: 0.1110 (0.1499)  loss_box_reg: 0.0857 (0.1439)  loss_objectness: 0.0085 (0.0128)  loss_rpn_box_reg: 0.0109 (0.0161)  time: 0.6817  data: 0.0007  max mem: 10941\n",
            "Epoch: [0]  [4056/4057]  eta: 0:00:00  lr: 0.005000  loss: 0.3445 (0.3226)  loss_classifier: 0.1414 (0.1499)  loss_box_reg: 0.1683 (0.1438)  loss_objectness: 0.0121 (0.0128)  loss_rpn_box_reg: 0.0107 (0.0161)  time: 0.6484  data: 0.0003  max mem: 10941\n",
            "Epoch: [0] Total time: 0:46:32 (0.6882 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:25  model_time: 0.2822 (0.2822)  evaluator_time: 0.0168 (0.0168)  time: 0.6481  data: 0.3474  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:38  model_time: 0.2849 (0.2891)  evaluator_time: 0.0112 (0.0109)  time: 0.2952  data: 0.0002  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2914 (0.2876)  evaluator_time: 0.0102 (0.0109)  time: 0.3106  data: 0.0004  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2911 (0.2871)  evaluator_time: 0.0102 (0.0110)  time: 0.2951  data: 0.0003  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.3019 s / it)\n",
            "Averaged stats: model_time: 0.2911 (0.2871)  evaluator_time: 0.0102 (0.0110)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.74s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:09  model_time: 0.2496 (0.2496)  evaluator_time: 0.0174 (0.0174)  time: 0.5758  data: 0.3073  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:38  model_time: 0.2875 (0.2920)  evaluator_time: 0.0119 (0.0115)  time: 0.2961  data: 0.0004  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2902 (0.2891)  evaluator_time: 0.0110 (0.0114)  time: 0.3113  data: 0.0006  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2892 (0.2882)  evaluator_time: 0.0113 (0.0115)  time: 0.2943  data: 0.0003  max mem: 10941\n",
            "Test: Total time: 0:01:08 (0.3035 s / it)\n",
            "Averaged stats: model_time: 0.2892 (0.2882)  evaluator_time: 0.0113 (0.0115)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.76s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.652\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.286\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.353\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
            "Epoch: [1]  [   0/4057]  eta: 1:23:06  lr: 0.005000  loss: 0.2064 (0.2064)  loss_classifier: 0.0946 (0.0946)  loss_box_reg: 0.0642 (0.0642)  loss_objectness: 0.0204 (0.0204)  loss_rpn_box_reg: 0.0272 (0.0272)  time: 1.2291  data: 0.3069  max mem: 10941\n",
            "Epoch: [1]  [ 100/4057]  eta: 0:44:28  lr: 0.005000  loss: 0.2332 (0.2355)  loss_classifier: 0.0910 (0.0982)  loss_box_reg: 0.1320 (0.1113)  loss_objectness: 0.0063 (0.0093)  loss_rpn_box_reg: 0.0129 (0.0167)  time: 0.6863  data: 0.0005  max mem: 10941\n",
            "Epoch: [1]  [ 200/4057]  eta: 0:43:53  lr: 0.005000  loss: 0.2022 (0.2381)  loss_classifier: 0.0798 (0.1006)  loss_box_reg: 0.0850 (0.1122)  loss_objectness: 0.0053 (0.0091)  loss_rpn_box_reg: 0.0151 (0.0162)  time: 0.6623  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [ 300/4057]  eta: 0:43:06  lr: 0.005000  loss: 0.1841 (0.2389)  loss_classifier: 0.0700 (0.1024)  loss_box_reg: 0.0862 (0.1120)  loss_objectness: 0.0049 (0.0089)  loss_rpn_box_reg: 0.0074 (0.0156)  time: 0.6981  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [ 400/4057]  eta: 0:42:05  lr: 0.005000  loss: 0.1858 (0.2317)  loss_classifier: 0.0776 (0.0990)  loss_box_reg: 0.0694 (0.1092)  loss_objectness: 0.0046 (0.0085)  loss_rpn_box_reg: 0.0115 (0.0151)  time: 0.6948  data: 0.0003  max mem: 10941\n",
            "Epoch: [1]  [ 500/4057]  eta: 0:40:46  lr: 0.005000  loss: 0.1457 (0.2355)  loss_classifier: 0.0681 (0.1005)  loss_box_reg: 0.0620 (0.1109)  loss_objectness: 0.0040 (0.0090)  loss_rpn_box_reg: 0.0100 (0.0152)  time: 0.7113  data: 0.0006  max mem: 10941\n",
            "Epoch: [1]  [ 600/4057]  eta: 0:39:33  lr: 0.005000  loss: 0.1695 (0.2318)  loss_classifier: 0.0685 (0.0983)  loss_box_reg: 0.0779 (0.1098)  loss_objectness: 0.0057 (0.0088)  loss_rpn_box_reg: 0.0090 (0.0150)  time: 0.6463  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [ 700/4057]  eta: 0:38:22  lr: 0.005000  loss: 0.2133 (0.2330)  loss_classifier: 0.0939 (0.0986)  loss_box_reg: 0.1021 (0.1104)  loss_objectness: 0.0074 (0.0089)  loss_rpn_box_reg: 0.0130 (0.0151)  time: 0.6811  data: 0.0003  max mem: 10941\n",
            "Epoch: [1]  [ 800/4057]  eta: 0:37:20  lr: 0.005000  loss: 0.2020 (0.2348)  loss_classifier: 0.1011 (0.0993)  loss_box_reg: 0.0906 (0.1115)  loss_objectness: 0.0046 (0.0087)  loss_rpn_box_reg: 0.0096 (0.0152)  time: 0.7303  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [ 900/4057]  eta: 0:36:11  lr: 0.005000  loss: 0.2364 (0.2361)  loss_classifier: 0.0941 (0.0998)  loss_box_reg: 0.1069 (0.1122)  loss_objectness: 0.0059 (0.0088)  loss_rpn_box_reg: 0.0153 (0.0153)  time: 0.7067  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1000/4057]  eta: 0:35:06  lr: 0.005000  loss: 0.2173 (0.2366)  loss_classifier: 0.0834 (0.1001)  loss_box_reg: 0.1073 (0.1125)  loss_objectness: 0.0053 (0.0088)  loss_rpn_box_reg: 0.0116 (0.0153)  time: 0.7132  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1100/4057]  eta: 0:33:55  lr: 0.005000  loss: 0.2037 (0.2366)  loss_classifier: 0.0870 (0.1000)  loss_box_reg: 0.1042 (0.1129)  loss_objectness: 0.0061 (0.0086)  loss_rpn_box_reg: 0.0105 (0.0152)  time: 0.6492  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1200/4057]  eta: 0:32:44  lr: 0.005000  loss: 0.2863 (0.2372)  loss_classifier: 0.1082 (0.1004)  loss_box_reg: 0.1256 (0.1132)  loss_objectness: 0.0082 (0.0085)  loss_rpn_box_reg: 0.0111 (0.0151)  time: 0.6882  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1300/4057]  eta: 0:31:30  lr: 0.005000  loss: 0.2671 (0.2384)  loss_classifier: 0.1017 (0.1008)  loss_box_reg: 0.1568 (0.1138)  loss_objectness: 0.0093 (0.0087)  loss_rpn_box_reg: 0.0134 (0.0151)  time: 0.6940  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1400/4057]  eta: 0:30:22  lr: 0.005000  loss: 0.2127 (0.2402)  loss_classifier: 0.0935 (0.1016)  loss_box_reg: 0.0971 (0.1142)  loss_objectness: 0.0116 (0.0090)  loss_rpn_box_reg: 0.0106 (0.0154)  time: 0.6711  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1500/4057]  eta: 0:29:12  lr: 0.005000  loss: 0.1939 (0.2409)  loss_classifier: 0.0993 (0.1018)  loss_box_reg: 0.0845 (0.1147)  loss_objectness: 0.0051 (0.0090)  loss_rpn_box_reg: 0.0103 (0.0154)  time: 0.6958  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1600/4057]  eta: 0:28:03  lr: 0.005000  loss: 0.2268 (0.2415)  loss_classifier: 0.1015 (0.1025)  loss_box_reg: 0.0940 (0.1148)  loss_objectness: 0.0078 (0.0090)  loss_rpn_box_reg: 0.0108 (0.0153)  time: 0.7357  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1700/4057]  eta: 0:26:56  lr: 0.005000  loss: 0.2773 (0.2420)  loss_classifier: 0.1050 (0.1027)  loss_box_reg: 0.1325 (0.1151)  loss_objectness: 0.0102 (0.0091)  loss_rpn_box_reg: 0.0114 (0.0152)  time: 0.6494  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1800/4057]  eta: 0:25:48  lr: 0.005000  loss: 0.1979 (0.2423)  loss_classifier: 0.0953 (0.1029)  loss_box_reg: 0.0869 (0.1151)  loss_objectness: 0.0068 (0.0090)  loss_rpn_box_reg: 0.0069 (0.0152)  time: 0.6600  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [1900/4057]  eta: 0:24:39  lr: 0.005000  loss: 0.1839 (0.2429)  loss_classifier: 0.0760 (0.1034)  loss_box_reg: 0.0756 (0.1153)  loss_objectness: 0.0050 (0.0090)  loss_rpn_box_reg: 0.0097 (0.0152)  time: 0.6430  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [2000/4057]  eta: 0:23:29  lr: 0.005000  loss: 0.1996 (0.2433)  loss_classifier: 0.0832 (0.1039)  loss_box_reg: 0.0832 (0.1152)  loss_objectness: 0.0056 (0.0091)  loss_rpn_box_reg: 0.0121 (0.0151)  time: 0.6492  data: 0.0007  max mem: 10941\n",
            "Epoch: [1]  [2100/4057]  eta: 0:22:19  lr: 0.005000  loss: 0.2439 (0.2439)  loss_classifier: 0.0980 (0.1043)  loss_box_reg: 0.1119 (0.1153)  loss_objectness: 0.0100 (0.0091)  loss_rpn_box_reg: 0.0135 (0.0152)  time: 0.6532  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [2200/4057]  eta: 0:21:11  lr: 0.005000  loss: 0.2065 (0.2451)  loss_classifier: 0.0819 (0.1049)  loss_box_reg: 0.1082 (0.1158)  loss_objectness: 0.0065 (0.0092)  loss_rpn_box_reg: 0.0125 (0.0152)  time: 0.6842  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [2300/4057]  eta: 0:20:03  lr: 0.005000  loss: 0.2263 (0.2459)  loss_classifier: 0.1104 (0.1053)  loss_box_reg: 0.1125 (0.1163)  loss_objectness: 0.0089 (0.0092)  loss_rpn_box_reg: 0.0137 (0.0151)  time: 0.7169  data: 0.0005  max mem: 10941\n",
            "Epoch: [1]  [2400/4057]  eta: 0:18:55  lr: 0.005000  loss: 0.2549 (0.2458)  loss_classifier: 0.1091 (0.1052)  loss_box_reg: 0.1264 (0.1161)  loss_objectness: 0.0083 (0.0093)  loss_rpn_box_reg: 0.0118 (0.0152)  time: 0.7032  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [2500/4057]  eta: 0:17:47  lr: 0.005000  loss: 0.2385 (0.2452)  loss_classifier: 0.1012 (0.1049)  loss_box_reg: 0.1040 (0.1158)  loss_objectness: 0.0072 (0.0093)  loss_rpn_box_reg: 0.0101 (0.0152)  time: 0.6911  data: 0.0003  max mem: 10941\n",
            "Epoch: [1]  [2600/4057]  eta: 0:16:38  lr: 0.005000  loss: 0.2370 (0.2465)  loss_classifier: 0.1046 (0.1056)  loss_box_reg: 0.0942 (0.1163)  loss_objectness: 0.0063 (0.0093)  loss_rpn_box_reg: 0.0178 (0.0152)  time: 0.6952  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [2700/4057]  eta: 0:15:30  lr: 0.005000  loss: 0.2450 (0.2472)  loss_classifier: 0.0854 (0.1058)  loss_box_reg: 0.1080 (0.1167)  loss_objectness: 0.0067 (0.0094)  loss_rpn_box_reg: 0.0092 (0.0153)  time: 0.6698  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [2800/4057]  eta: 0:14:22  lr: 0.005000  loss: 0.2263 (0.2483)  loss_classifier: 0.0938 (0.1064)  loss_box_reg: 0.1053 (0.1172)  loss_objectness: 0.0061 (0.0094)  loss_rpn_box_reg: 0.0097 (0.0153)  time: 0.7339  data: 0.0007  max mem: 10941\n",
            "Epoch: [1]  [2900/4057]  eta: 0:13:14  lr: 0.005000  loss: 0.1803 (0.2485)  loss_classifier: 0.0815 (0.1064)  loss_box_reg: 0.0892 (0.1173)  loss_objectness: 0.0049 (0.0095)  loss_rpn_box_reg: 0.0106 (0.0153)  time: 0.7124  data: 0.0006  max mem: 10941\n",
            "Epoch: [1]  [3000/4057]  eta: 0:12:06  lr: 0.005000  loss: 0.2293 (0.2488)  loss_classifier: 0.0977 (0.1066)  loss_box_reg: 0.0969 (0.1173)  loss_objectness: 0.0078 (0.0095)  loss_rpn_box_reg: 0.0170 (0.0153)  time: 0.6879  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [3100/4057]  eta: 0:10:57  lr: 0.005000  loss: 0.2061 (0.2488)  loss_classifier: 0.0871 (0.1066)  loss_box_reg: 0.1070 (0.1173)  loss_objectness: 0.0055 (0.0095)  loss_rpn_box_reg: 0.0128 (0.0153)  time: 0.6956  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [3200/4057]  eta: 0:09:48  lr: 0.005000  loss: 0.2358 (0.2488)  loss_classifier: 0.0943 (0.1066)  loss_box_reg: 0.1012 (0.1173)  loss_objectness: 0.0096 (0.0095)  loss_rpn_box_reg: 0.0119 (0.0153)  time: 0.6828  data: 0.0003  max mem: 10941\n",
            "Epoch: [1]  [3300/4057]  eta: 0:08:40  lr: 0.005000  loss: 0.1863 (0.2482)  loss_classifier: 0.0725 (0.1063)  loss_box_reg: 0.0895 (0.1171)  loss_objectness: 0.0072 (0.0095)  loss_rpn_box_reg: 0.0133 (0.0154)  time: 0.6796  data: 0.0006  max mem: 10941\n",
            "Epoch: [1]  [3400/4057]  eta: 0:07:31  lr: 0.005000  loss: 0.1691 (0.2483)  loss_classifier: 0.0866 (0.1063)  loss_box_reg: 0.0973 (0.1171)  loss_objectness: 0.0068 (0.0095)  loss_rpn_box_reg: 0.0187 (0.0154)  time: 0.6979  data: 0.0003  max mem: 10941\n",
            "Epoch: [1]  [3500/4057]  eta: 0:06:22  lr: 0.005000  loss: 0.2592 (0.2489)  loss_classifier: 0.1219 (0.1067)  loss_box_reg: 0.1141 (0.1172)  loss_objectness: 0.0083 (0.0095)  loss_rpn_box_reg: 0.0118 (0.0155)  time: 0.6950  data: 0.0005  max mem: 10941\n",
            "Epoch: [1]  [3600/4057]  eta: 0:05:14  lr: 0.005000  loss: 0.1759 (0.2493)  loss_classifier: 0.0831 (0.1069)  loss_box_reg: 0.0744 (0.1173)  loss_objectness: 0.0057 (0.0095)  loss_rpn_box_reg: 0.0115 (0.0155)  time: 0.6988  data: 0.0003  max mem: 10941\n",
            "Epoch: [1]  [3700/4057]  eta: 0:04:05  lr: 0.005000  loss: 0.2483 (0.2497)  loss_classifier: 0.0941 (0.1071)  loss_box_reg: 0.1128 (0.1174)  loss_objectness: 0.0100 (0.0096)  loss_rpn_box_reg: 0.0192 (0.0155)  time: 0.6791  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [3800/4057]  eta: 0:02:56  lr: 0.005000  loss: 0.2233 (0.2502)  loss_classifier: 0.1106 (0.1074)  loss_box_reg: 0.1084 (0.1177)  loss_objectness: 0.0088 (0.0096)  loss_rpn_box_reg: 0.0138 (0.0155)  time: 0.6971  data: 0.0003  max mem: 10941\n",
            "Epoch: [1]  [3900/4057]  eta: 0:01:47  lr: 0.005000  loss: 0.2473 (0.2502)  loss_classifier: 0.0978 (0.1074)  loss_box_reg: 0.1151 (0.1177)  loss_objectness: 0.0080 (0.0097)  loss_rpn_box_reg: 0.0139 (0.0155)  time: 0.6957  data: 0.0002  max mem: 10941\n",
            "Epoch: [1]  [4000/4057]  eta: 0:00:39  lr: 0.005000  loss: 0.2649 (0.2501)  loss_classifier: 0.1181 (0.1074)  loss_box_reg: 0.1095 (0.1176)  loss_objectness: 0.0097 (0.0097)  loss_rpn_box_reg: 0.0107 (0.0155)  time: 0.7037  data: 0.0005  max mem: 10941\n",
            "Epoch: [1]  [4056/4057]  eta: 0:00:00  lr: 0.005000  loss: 0.2328 (0.2501)  loss_classifier: 0.0991 (0.1074)  loss_box_reg: 0.1084 (0.1175)  loss_objectness: 0.0069 (0.0097)  loss_rpn_box_reg: 0.0190 (0.0155)  time: 0.6815  data: 0.0003  max mem: 10941\n",
            "Epoch: [1] Total time: 0:46:32 (0.6883 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:16  model_time: 0.2867 (0.2867)  evaluator_time: 0.0099 (0.0099)  time: 0.6052  data: 0.3069  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2859 (0.2882)  evaluator_time: 0.0097 (0.0092)  time: 0.2925  data: 0.0001  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2860 (0.2869)  evaluator_time: 0.0101 (0.0093)  time: 0.3088  data: 0.0006  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2884 (0.2864)  evaluator_time: 0.0113 (0.0096)  time: 0.2936  data: 0.0001  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.2994 s / it)\n",
            "Averaged stats: model_time: 0.2884 (0.2864)  evaluator_time: 0.0113 (0.0096)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.59s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:44  model_time: 0.2385 (0.2385)  evaluator_time: 0.0113 (0.0113)  time: 0.7328  data: 0.4815  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:38  model_time: 0.2883 (0.2884)  evaluator_time: 0.0091 (0.0094)  time: 0.2936  data: 0.0003  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2899 (0.2870)  evaluator_time: 0.0101 (0.0095)  time: 0.3091  data: 0.0004  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2877 (0.2877)  evaluator_time: 0.0103 (0.0097)  time: 0.3084  data: 0.0005  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.3018 s / it)\n",
            "Averaged stats: model_time: 0.2877 (0.2877)  evaluator_time: 0.0103 (0.0097)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.59s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.660\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
            "Epoch: [2]  [   0/4057]  eta: 1:02:18  lr: 0.005000  loss: 0.3449 (0.3449)  loss_classifier: 0.1848 (0.1848)  loss_box_reg: 0.1483 (0.1483)  loss_objectness: 0.0068 (0.0068)  loss_rpn_box_reg: 0.0050 (0.0050)  time: 0.9214  data: 0.3361  max mem: 10941\n",
            "Epoch: [2]  [ 100/4057]  eta: 0:47:10  lr: 0.005000  loss: 0.2009 (0.2116)  loss_classifier: 0.0867 (0.0915)  loss_box_reg: 0.0960 (0.0989)  loss_objectness: 0.0050 (0.0074)  loss_rpn_box_reg: 0.0141 (0.0137)  time: 0.7582  data: 0.0006  max mem: 10941\n",
            "Epoch: [2]  [ 200/4057]  eta: 0:45:07  lr: 0.005000  loss: 0.2346 (0.2204)  loss_classifier: 0.1004 (0.0955)  loss_box_reg: 0.1150 (0.1028)  loss_objectness: 0.0057 (0.0077)  loss_rpn_box_reg: 0.0152 (0.0144)  time: 0.6893  data: 0.0003  max mem: 10941\n",
            "Epoch: [2]  [ 300/4057]  eta: 0:43:50  lr: 0.005000  loss: 0.2158 (0.2288)  loss_classifier: 0.1127 (0.0988)  loss_box_reg: 0.1232 (0.1077)  loss_objectness: 0.0054 (0.0076)  loss_rpn_box_reg: 0.0099 (0.0147)  time: 0.6950  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [ 400/4057]  eta: 0:42:22  lr: 0.005000  loss: 0.1830 (0.2303)  loss_classifier: 0.0728 (0.0977)  loss_box_reg: 0.0919 (0.1104)  loss_objectness: 0.0048 (0.0074)  loss_rpn_box_reg: 0.0090 (0.0149)  time: 0.6967  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [ 500/4057]  eta: 0:41:03  lr: 0.005000  loss: 0.2436 (0.2332)  loss_classifier: 0.0967 (0.0988)  loss_box_reg: 0.1117 (0.1116)  loss_objectness: 0.0076 (0.0076)  loss_rpn_box_reg: 0.0089 (0.0152)  time: 0.6629  data: 0.0007  max mem: 10941\n",
            "Epoch: [2]  [ 600/4057]  eta: 0:39:54  lr: 0.005000  loss: 0.2227 (0.2353)  loss_classifier: 0.0801 (0.1000)  loss_box_reg: 0.0759 (0.1117)  loss_objectness: 0.0055 (0.0082)  loss_rpn_box_reg: 0.0126 (0.0155)  time: 0.6846  data: 0.0004  max mem: 10941\n",
            "Epoch: [2]  [ 700/4057]  eta: 0:38:41  lr: 0.005000  loss: 0.1980 (0.2380)  loss_classifier: 0.0939 (0.1017)  loss_box_reg: 0.0696 (0.1124)  loss_objectness: 0.0070 (0.0084)  loss_rpn_box_reg: 0.0161 (0.0155)  time: 0.6915  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [ 800/4057]  eta: 0:37:29  lr: 0.005000  loss: 0.2428 (0.2381)  loss_classifier: 0.1064 (0.1018)  loss_box_reg: 0.1147 (0.1125)  loss_objectness: 0.0089 (0.0084)  loss_rpn_box_reg: 0.0109 (0.0153)  time: 0.7065  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [ 900/4057]  eta: 0:36:16  lr: 0.005000  loss: 0.2554 (0.2388)  loss_classifier: 0.0978 (0.1021)  loss_box_reg: 0.1037 (0.1128)  loss_objectness: 0.0089 (0.0085)  loss_rpn_box_reg: 0.0105 (0.0154)  time: 0.6839  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [1000/4057]  eta: 0:35:03  lr: 0.005000  loss: 0.1877 (0.2395)  loss_classifier: 0.0822 (0.1023)  loss_box_reg: 0.0892 (0.1130)  loss_objectness: 0.0047 (0.0086)  loss_rpn_box_reg: 0.0117 (0.0156)  time: 0.6940  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [1100/4057]  eta: 0:33:53  lr: 0.005000  loss: 0.1828 (0.2400)  loss_classifier: 0.0761 (0.1025)  loss_box_reg: 0.0802 (0.1134)  loss_objectness: 0.0058 (0.0086)  loss_rpn_box_reg: 0.0100 (0.0156)  time: 0.7173  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [1200/4057]  eta: 0:32:46  lr: 0.005000  loss: 0.2045 (0.2418)  loss_classifier: 0.0858 (0.1034)  loss_box_reg: 0.1123 (0.1144)  loss_objectness: 0.0069 (0.0085)  loss_rpn_box_reg: 0.0159 (0.0155)  time: 0.6854  data: 0.0003  max mem: 10941\n",
            "Epoch: [2]  [1300/4057]  eta: 0:31:39  lr: 0.005000  loss: 0.2050 (0.2403)  loss_classifier: 0.0915 (0.1030)  loss_box_reg: 0.0818 (0.1133)  loss_objectness: 0.0067 (0.0084)  loss_rpn_box_reg: 0.0124 (0.0155)  time: 0.7456  data: 0.0004  max mem: 10941\n",
            "Epoch: [2]  [1400/4057]  eta: 0:30:31  lr: 0.005000  loss: 0.1700 (0.2404)  loss_classifier: 0.0784 (0.1030)  loss_box_reg: 0.0834 (0.1135)  loss_objectness: 0.0067 (0.0084)  loss_rpn_box_reg: 0.0137 (0.0155)  time: 0.6776  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [1500/4057]  eta: 0:29:21  lr: 0.005000  loss: 0.1636 (0.2398)  loss_classifier: 0.0737 (0.1026)  loss_box_reg: 0.0786 (0.1134)  loss_objectness: 0.0046 (0.0084)  loss_rpn_box_reg: 0.0103 (0.0153)  time: 0.6828  data: 0.0004  max mem: 10941\n",
            "Epoch: [2]  [1600/4057]  eta: 0:28:12  lr: 0.005000  loss: 0.2048 (0.2389)  loss_classifier: 0.0794 (0.1023)  loss_box_reg: 0.0890 (0.1130)  loss_objectness: 0.0051 (0.0083)  loss_rpn_box_reg: 0.0095 (0.0152)  time: 0.6909  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [1700/4057]  eta: 0:27:04  lr: 0.005000  loss: 0.2483 (0.2393)  loss_classifier: 0.1103 (0.1024)  loss_box_reg: 0.1133 (0.1133)  loss_objectness: 0.0075 (0.0083)  loss_rpn_box_reg: 0.0130 (0.0153)  time: 0.7098  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [1800/4057]  eta: 0:25:56  lr: 0.005000  loss: 0.1565 (0.2394)  loss_classifier: 0.0714 (0.1025)  loss_box_reg: 0.0798 (0.1132)  loss_objectness: 0.0061 (0.0084)  loss_rpn_box_reg: 0.0112 (0.0153)  time: 0.6793  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [1900/4057]  eta: 0:24:48  lr: 0.005000  loss: 0.2283 (0.2393)  loss_classifier: 0.0995 (0.1026)  loss_box_reg: 0.0894 (0.1130)  loss_objectness: 0.0050 (0.0083)  loss_rpn_box_reg: 0.0136 (0.0153)  time: 0.7652  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2000/4057]  eta: 0:23:37  lr: 0.005000  loss: 0.2018 (0.2399)  loss_classifier: 0.0963 (0.1029)  loss_box_reg: 0.0853 (0.1133)  loss_objectness: 0.0109 (0.0084)  loss_rpn_box_reg: 0.0148 (0.0153)  time: 0.6480  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2100/4057]  eta: 0:22:28  lr: 0.005000  loss: 0.2158 (0.2401)  loss_classifier: 0.0953 (0.1030)  loss_box_reg: 0.0963 (0.1135)  loss_objectness: 0.0064 (0.0084)  loss_rpn_box_reg: 0.0076 (0.0152)  time: 0.7021  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2200/4057]  eta: 0:21:19  lr: 0.005000  loss: 0.1814 (0.2406)  loss_classifier: 0.0701 (0.1033)  loss_box_reg: 0.0813 (0.1136)  loss_objectness: 0.0062 (0.0085)  loss_rpn_box_reg: 0.0124 (0.0153)  time: 0.6761  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2300/4057]  eta: 0:20:10  lr: 0.005000  loss: 0.1983 (0.2414)  loss_classifier: 0.0947 (0.1038)  loss_box_reg: 0.0828 (0.1137)  loss_objectness: 0.0059 (0.0086)  loss_rpn_box_reg: 0.0120 (0.0153)  time: 0.7124  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2400/4057]  eta: 0:19:02  lr: 0.005000  loss: 0.2454 (0.2416)  loss_classifier: 0.1011 (0.1039)  loss_box_reg: 0.1228 (0.1138)  loss_objectness: 0.0069 (0.0086)  loss_rpn_box_reg: 0.0097 (0.0154)  time: 0.7277  data: 0.0003  max mem: 10941\n",
            "Epoch: [2]  [2500/4057]  eta: 0:17:52  lr: 0.005000  loss: 0.2505 (0.2419)  loss_classifier: 0.1140 (0.1041)  loss_box_reg: 0.1042 (0.1137)  loss_objectness: 0.0113 (0.0086)  loss_rpn_box_reg: 0.0136 (0.0154)  time: 0.6840  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2600/4057]  eta: 0:16:44  lr: 0.005000  loss: 0.1560 (0.2415)  loss_classifier: 0.0635 (0.1039)  loss_box_reg: 0.0652 (0.1135)  loss_objectness: 0.0050 (0.0086)  loss_rpn_box_reg: 0.0112 (0.0154)  time: 0.6953  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2700/4057]  eta: 0:15:35  lr: 0.005000  loss: 0.3075 (0.2418)  loss_classifier: 0.1307 (0.1042)  loss_box_reg: 0.1458 (0.1136)  loss_objectness: 0.0072 (0.0086)  loss_rpn_box_reg: 0.0127 (0.0155)  time: 0.6764  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2800/4057]  eta: 0:14:26  lr: 0.005000  loss: 0.2539 (0.2425)  loss_classifier: 0.1149 (0.1046)  loss_box_reg: 0.1102 (0.1138)  loss_objectness: 0.0106 (0.0086)  loss_rpn_box_reg: 0.0114 (0.0154)  time: 0.6863  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [2900/4057]  eta: 0:13:17  lr: 0.005000  loss: 0.2075 (0.2429)  loss_classifier: 0.0854 (0.1049)  loss_box_reg: 0.1113 (0.1140)  loss_objectness: 0.0043 (0.0086)  loss_rpn_box_reg: 0.0096 (0.0154)  time: 0.6927  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3000/4057]  eta: 0:12:09  lr: 0.005000  loss: 0.2550 (0.2432)  loss_classifier: 0.1083 (0.1051)  loss_box_reg: 0.0958 (0.1140)  loss_objectness: 0.0059 (0.0086)  loss_rpn_box_reg: 0.0241 (0.0155)  time: 0.7006  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3100/4057]  eta: 0:11:00  lr: 0.005000  loss: 0.2066 (0.2437)  loss_classifier: 0.0813 (0.1053)  loss_box_reg: 0.0972 (0.1142)  loss_objectness: 0.0079 (0.0087)  loss_rpn_box_reg: 0.0103 (0.0155)  time: 0.6665  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3200/4057]  eta: 0:09:50  lr: 0.005000  loss: 0.2233 (0.2439)  loss_classifier: 0.1008 (0.1055)  loss_box_reg: 0.1052 (0.1143)  loss_objectness: 0.0060 (0.0087)  loss_rpn_box_reg: 0.0076 (0.0154)  time: 0.6992  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3300/4057]  eta: 0:08:41  lr: 0.005000  loss: 0.2122 (0.2437)  loss_classifier: 0.0966 (0.1055)  loss_box_reg: 0.0939 (0.1141)  loss_objectness: 0.0059 (0.0087)  loss_rpn_box_reg: 0.0123 (0.0154)  time: 0.6715  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3400/4057]  eta: 0:07:33  lr: 0.005000  loss: 0.1930 (0.2441)  loss_classifier: 0.0824 (0.1057)  loss_box_reg: 0.0935 (0.1143)  loss_objectness: 0.0063 (0.0087)  loss_rpn_box_reg: 0.0108 (0.0154)  time: 0.6980  data: 0.0003  max mem: 10941\n",
            "Epoch: [2]  [3500/4057]  eta: 0:06:24  lr: 0.005000  loss: 0.2035 (0.2446)  loss_classifier: 0.0985 (0.1060)  loss_box_reg: 0.0899 (0.1143)  loss_objectness: 0.0085 (0.0088)  loss_rpn_box_reg: 0.0140 (0.0155)  time: 0.7227  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3600/4057]  eta: 0:05:14  lr: 0.005000  loss: 0.1833 (0.2442)  loss_classifier: 0.0826 (0.1058)  loss_box_reg: 0.0904 (0.1142)  loss_objectness: 0.0056 (0.0088)  loss_rpn_box_reg: 0.0109 (0.0155)  time: 0.6609  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3700/4057]  eta: 0:04:06  lr: 0.005000  loss: 0.2539 (0.2442)  loss_classifier: 0.1014 (0.1059)  loss_box_reg: 0.1086 (0.1140)  loss_objectness: 0.0092 (0.0088)  loss_rpn_box_reg: 0.0142 (0.0154)  time: 0.6803  data: 0.0003  max mem: 10941\n",
            "Epoch: [2]  [3800/4057]  eta: 0:02:57  lr: 0.005000  loss: 0.2410 (0.2438)  loss_classifier: 0.0933 (0.1057)  loss_box_reg: 0.1088 (0.1138)  loss_objectness: 0.0063 (0.0088)  loss_rpn_box_reg: 0.0105 (0.0154)  time: 0.6792  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [3900/4057]  eta: 0:01:48  lr: 0.005000  loss: 0.1968 (0.2442)  loss_classifier: 0.0813 (0.1059)  loss_box_reg: 0.0845 (0.1141)  loss_objectness: 0.0066 (0.0088)  loss_rpn_box_reg: 0.0204 (0.0154)  time: 0.7128  data: 0.0003  max mem: 10941\n",
            "Epoch: [2]  [4000/4057]  eta: 0:00:39  lr: 0.005000  loss: 0.2985 (0.2446)  loss_classifier: 0.1287 (0.1061)  loss_box_reg: 0.1272 (0.1142)  loss_objectness: 0.0091 (0.0088)  loss_rpn_box_reg: 0.0117 (0.0154)  time: 0.6585  data: 0.0002  max mem: 10941\n",
            "Epoch: [2]  [4056/4057]  eta: 0:00:00  lr: 0.005000  loss: 0.1882 (0.2450)  loss_classifier: 0.0900 (0.1063)  loss_box_reg: 0.0820 (0.1144)  loss_objectness: 0.0067 (0.0089)  loss_rpn_box_reg: 0.0113 (0.0154)  time: 0.6676  data: 0.0004  max mem: 10941\n",
            "Epoch: [2] Total time: 0:46:37 (0.6895 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:36  model_time: 0.2371 (0.2371)  evaluator_time: 0.0125 (0.0125)  time: 0.6976  data: 0.4465  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2844 (0.2876)  evaluator_time: 0.0099 (0.0100)  time: 0.2936  data: 0.0002  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2898 (0.2865)  evaluator_time: 0.0098 (0.0100)  time: 0.3098  data: 0.0007  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2892 (0.2860)  evaluator_time: 0.0111 (0.0102)  time: 0.2945  data: 0.0003  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.3004 s / it)\n",
            "Averaged stats: model_time: 0.2892 (0.2860)  evaluator_time: 0.0111 (0.0102)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.66s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:25  model_time: 0.2688 (0.2688)  evaluator_time: 0.0139 (0.0139)  time: 0.6462  data: 0.3619  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:38  model_time: 0.2855 (0.2889)  evaluator_time: 0.0098 (0.0103)  time: 0.2948  data: 0.0003  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2893 (0.2871)  evaluator_time: 0.0097 (0.0102)  time: 0.3090  data: 0.0004  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2941 (0.2866)  evaluator_time: 0.0106 (0.0103)  time: 0.2945  data: 0.0003  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.3007 s / it)\n",
            "Averaged stats: model_time: 0.2941 (0.2866)  evaluator_time: 0.0106 (0.0103)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.70s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.614\n",
            "Epoch: [3]  [   0/4057]  eta: 1:21:01  lr: 0.000500  loss: 0.2639 (0.2639)  loss_classifier: 0.1438 (0.1438)  loss_box_reg: 0.0996 (0.0996)  loss_objectness: 0.0098 (0.0098)  loss_rpn_box_reg: 0.0107 (0.0107)  time: 1.1983  data: 0.4404  max mem: 10941\n",
            "Epoch: [3]  [ 100/4057]  eta: 0:46:26  lr: 0.000500  loss: 0.2134 (0.2363)  loss_classifier: 0.0864 (0.0970)  loss_box_reg: 0.1093 (0.1165)  loss_objectness: 0.0053 (0.0078)  loss_rpn_box_reg: 0.0098 (0.0150)  time: 0.7068  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [ 200/4057]  eta: 0:44:21  lr: 0.000500  loss: 0.1793 (0.2242)  loss_classifier: 0.0723 (0.0926)  loss_box_reg: 0.0853 (0.1095)  loss_objectness: 0.0036 (0.0075)  loss_rpn_box_reg: 0.0097 (0.0147)  time: 0.6773  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [ 300/4057]  eta: 0:42:58  lr: 0.000500  loss: 0.1943 (0.2185)  loss_classifier: 0.0884 (0.0902)  loss_box_reg: 0.0770 (0.1065)  loss_objectness: 0.0043 (0.0073)  loss_rpn_box_reg: 0.0123 (0.0145)  time: 0.6940  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [ 400/4057]  eta: 0:41:49  lr: 0.000500  loss: 0.1570 (0.2133)  loss_classifier: 0.0631 (0.0888)  loss_box_reg: 0.0717 (0.1031)  loss_objectness: 0.0045 (0.0070)  loss_rpn_box_reg: 0.0107 (0.0144)  time: 0.7224  data: 0.0007  max mem: 10941\n",
            "Epoch: [3]  [ 500/4057]  eta: 0:40:46  lr: 0.000500  loss: 0.1693 (0.2120)  loss_classifier: 0.0737 (0.0877)  loss_box_reg: 0.0903 (0.1027)  loss_objectness: 0.0059 (0.0069)  loss_rpn_box_reg: 0.0128 (0.0147)  time: 0.6626  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [ 600/4057]  eta: 0:39:43  lr: 0.000500  loss: 0.1746 (0.2086)  loss_classifier: 0.0658 (0.0862)  loss_box_reg: 0.0921 (0.1013)  loss_objectness: 0.0040 (0.0068)  loss_rpn_box_reg: 0.0087 (0.0143)  time: 0.6975  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [ 700/4057]  eta: 0:38:38  lr: 0.000500  loss: 0.1532 (0.2072)  loss_classifier: 0.0662 (0.0850)  loss_box_reg: 0.0761 (0.1011)  loss_objectness: 0.0047 (0.0068)  loss_rpn_box_reg: 0.0119 (0.0143)  time: 0.6799  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [ 800/4057]  eta: 0:37:32  lr: 0.000500  loss: 0.1544 (0.2063)  loss_classifier: 0.0679 (0.0844)  loss_box_reg: 0.0675 (0.1007)  loss_objectness: 0.0055 (0.0068)  loss_rpn_box_reg: 0.0114 (0.0143)  time: 0.7262  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [ 900/4057]  eta: 0:36:18  lr: 0.000500  loss: 0.1697 (0.2051)  loss_classifier: 0.0620 (0.0840)  loss_box_reg: 0.0687 (0.1003)  loss_objectness: 0.0040 (0.0066)  loss_rpn_box_reg: 0.0086 (0.0143)  time: 0.6574  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [1000/4057]  eta: 0:35:08  lr: 0.000500  loss: 0.1372 (0.2019)  loss_classifier: 0.0608 (0.0826)  loss_box_reg: 0.0638 (0.0986)  loss_objectness: 0.0057 (0.0065)  loss_rpn_box_reg: 0.0118 (0.0142)  time: 0.6904  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [1100/4057]  eta: 0:33:59  lr: 0.000500  loss: 0.1857 (0.1999)  loss_classifier: 0.0716 (0.0817)  loss_box_reg: 0.0908 (0.0979)  loss_objectness: 0.0028 (0.0063)  loss_rpn_box_reg: 0.0063 (0.0139)  time: 0.7024  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [1200/4057]  eta: 0:32:51  lr: 0.000500  loss: 0.1722 (0.2002)  loss_classifier: 0.0700 (0.0817)  loss_box_reg: 0.0813 (0.0982)  loss_objectness: 0.0043 (0.0063)  loss_rpn_box_reg: 0.0111 (0.0141)  time: 0.7042  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [1300/4057]  eta: 0:31:40  lr: 0.000500  loss: 0.1402 (0.1995)  loss_classifier: 0.0624 (0.0813)  loss_box_reg: 0.0753 (0.0979)  loss_objectness: 0.0033 (0.0062)  loss_rpn_box_reg: 0.0113 (0.0140)  time: 0.6732  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [1400/4057]  eta: 0:30:31  lr: 0.000500  loss: 0.1558 (0.1979)  loss_classifier: 0.0579 (0.0806)  loss_box_reg: 0.0779 (0.0972)  loss_objectness: 0.0032 (0.0062)  loss_rpn_box_reg: 0.0112 (0.0140)  time: 0.6689  data: 0.0006  max mem: 10941\n",
            "Epoch: [3]  [1500/4057]  eta: 0:29:21  lr: 0.000500  loss: 0.1699 (0.1970)  loss_classifier: 0.0657 (0.0802)  loss_box_reg: 0.0792 (0.0968)  loss_objectness: 0.0035 (0.0061)  loss_rpn_box_reg: 0.0072 (0.0139)  time: 0.6767  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [1600/4057]  eta: 0:28:10  lr: 0.000500  loss: 0.1355 (0.1961)  loss_classifier: 0.0623 (0.0800)  loss_box_reg: 0.0655 (0.0963)  loss_objectness: 0.0034 (0.0061)  loss_rpn_box_reg: 0.0091 (0.0137)  time: 0.7243  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [1700/4057]  eta: 0:27:03  lr: 0.000500  loss: 0.1221 (0.1957)  loss_classifier: 0.0460 (0.0798)  loss_box_reg: 0.0551 (0.0962)  loss_objectness: 0.0038 (0.0061)  loss_rpn_box_reg: 0.0074 (0.0136)  time: 0.6810  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [1800/4057]  eta: 0:25:55  lr: 0.000500  loss: 0.1832 (0.1949)  loss_classifier: 0.0733 (0.0795)  loss_box_reg: 0.0867 (0.0958)  loss_objectness: 0.0038 (0.0060)  loss_rpn_box_reg: 0.0114 (0.0136)  time: 0.7033  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [1900/4057]  eta: 0:24:43  lr: 0.000500  loss: 0.1375 (0.1946)  loss_classifier: 0.0611 (0.0795)  loss_box_reg: 0.0727 (0.0955)  loss_objectness: 0.0037 (0.0061)  loss_rpn_box_reg: 0.0058 (0.0135)  time: 0.6744  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [2000/4057]  eta: 0:23:36  lr: 0.000500  loss: 0.1678 (0.1942)  loss_classifier: 0.0735 (0.0793)  loss_box_reg: 0.0829 (0.0953)  loss_objectness: 0.0036 (0.0060)  loss_rpn_box_reg: 0.0125 (0.0135)  time: 0.7304  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [2100/4057]  eta: 0:22:26  lr: 0.000500  loss: 0.1195 (0.1932)  loss_classifier: 0.0524 (0.0788)  loss_box_reg: 0.0550 (0.0950)  loss_objectness: 0.0031 (0.0059)  loss_rpn_box_reg: 0.0058 (0.0134)  time: 0.6452  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [2200/4057]  eta: 0:21:17  lr: 0.000500  loss: 0.1428 (0.1934)  loss_classifier: 0.0563 (0.0788)  loss_box_reg: 0.0713 (0.0952)  loss_objectness: 0.0036 (0.0060)  loss_rpn_box_reg: 0.0114 (0.0134)  time: 0.6545  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [2300/4057]  eta: 0:20:10  lr: 0.000500  loss: 0.1911 (0.1933)  loss_classifier: 0.0716 (0.0787)  loss_box_reg: 0.0960 (0.0952)  loss_objectness: 0.0054 (0.0060)  loss_rpn_box_reg: 0.0154 (0.0134)  time: 0.7175  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [2400/4057]  eta: 0:19:00  lr: 0.000500  loss: 0.1896 (0.1936)  loss_classifier: 0.0707 (0.0787)  loss_box_reg: 0.0902 (0.0955)  loss_objectness: 0.0057 (0.0060)  loss_rpn_box_reg: 0.0111 (0.0135)  time: 0.6650  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [2500/4057]  eta: 0:17:52  lr: 0.000500  loss: 0.2031 (0.1935)  loss_classifier: 0.0939 (0.0787)  loss_box_reg: 0.0870 (0.0954)  loss_objectness: 0.0051 (0.0059)  loss_rpn_box_reg: 0.0111 (0.0134)  time: 0.6826  data: 0.0007  max mem: 10941\n",
            "Epoch: [3]  [2600/4057]  eta: 0:16:42  lr: 0.000500  loss: 0.1829 (0.1935)  loss_classifier: 0.0703 (0.0787)  loss_box_reg: 0.0838 (0.0954)  loss_objectness: 0.0047 (0.0059)  loss_rpn_box_reg: 0.0087 (0.0134)  time: 0.6194  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [2700/4057]  eta: 0:15:33  lr: 0.000500  loss: 0.1558 (0.1926)  loss_classifier: 0.0629 (0.0783)  loss_box_reg: 0.0657 (0.0950)  loss_objectness: 0.0044 (0.0059)  loss_rpn_box_reg: 0.0110 (0.0133)  time: 0.7171  data: 0.0006  max mem: 10941\n",
            "Epoch: [3]  [2800/4057]  eta: 0:14:24  lr: 0.000500  loss: 0.1539 (0.1929)  loss_classifier: 0.0619 (0.0784)  loss_box_reg: 0.0820 (0.0952)  loss_objectness: 0.0028 (0.0059)  loss_rpn_box_reg: 0.0095 (0.0133)  time: 0.6627  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [2900/4057]  eta: 0:13:15  lr: 0.000500  loss: 0.1913 (0.1925)  loss_classifier: 0.0730 (0.0782)  loss_box_reg: 0.0912 (0.0952)  loss_objectness: 0.0036 (0.0059)  loss_rpn_box_reg: 0.0095 (0.0133)  time: 0.6949  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [3000/4057]  eta: 0:12:07  lr: 0.000500  loss: 0.1615 (0.1925)  loss_classifier: 0.0657 (0.0782)  loss_box_reg: 0.0670 (0.0952)  loss_objectness: 0.0045 (0.0058)  loss_rpn_box_reg: 0.0116 (0.0133)  time: 0.7027  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [3100/4057]  eta: 0:10:58  lr: 0.000500  loss: 0.1331 (0.1923)  loss_classifier: 0.0605 (0.0781)  loss_box_reg: 0.0564 (0.0951)  loss_objectness: 0.0031 (0.0058)  loss_rpn_box_reg: 0.0076 (0.0133)  time: 0.6837  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [3200/4057]  eta: 0:09:49  lr: 0.000500  loss: 0.1430 (0.1923)  loss_classifier: 0.0656 (0.0781)  loss_box_reg: 0.0715 (0.0952)  loss_objectness: 0.0029 (0.0058)  loss_rpn_box_reg: 0.0087 (0.0133)  time: 0.7000  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [3300/4057]  eta: 0:08:39  lr: 0.000500  loss: 0.1793 (0.1922)  loss_classifier: 0.0671 (0.0781)  loss_box_reg: 0.0871 (0.0951)  loss_objectness: 0.0032 (0.0058)  loss_rpn_box_reg: 0.0076 (0.0133)  time: 0.7163  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [3400/4057]  eta: 0:07:31  lr: 0.000500  loss: 0.1267 (0.1919)  loss_classifier: 0.0503 (0.0779)  loss_box_reg: 0.0673 (0.0950)  loss_objectness: 0.0037 (0.0057)  loss_rpn_box_reg: 0.0109 (0.0133)  time: 0.6849  data: 0.0003  max mem: 10941\n",
            "Epoch: [3]  [3500/4057]  eta: 0:06:22  lr: 0.000500  loss: 0.1774 (0.1914)  loss_classifier: 0.0699 (0.0777)  loss_box_reg: 0.0816 (0.0948)  loss_objectness: 0.0044 (0.0057)  loss_rpn_box_reg: 0.0101 (0.0132)  time: 0.6956  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [3600/4057]  eta: 0:05:14  lr: 0.000500  loss: 0.1364 (0.1912)  loss_classifier: 0.0632 (0.0776)  loss_box_reg: 0.0807 (0.0948)  loss_objectness: 0.0056 (0.0057)  loss_rpn_box_reg: 0.0091 (0.0131)  time: 0.6779  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [3700/4057]  eta: 0:04:05  lr: 0.000500  loss: 0.1795 (0.1910)  loss_classifier: 0.0771 (0.0775)  loss_box_reg: 0.0855 (0.0947)  loss_objectness: 0.0031 (0.0057)  loss_rpn_box_reg: 0.0085 (0.0132)  time: 0.7333  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [3800/4057]  eta: 0:02:56  lr: 0.000500  loss: 0.1970 (0.1906)  loss_classifier: 0.0780 (0.0773)  loss_box_reg: 0.1038 (0.0945)  loss_objectness: 0.0053 (0.0057)  loss_rpn_box_reg: 0.0099 (0.0131)  time: 0.6694  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [3900/4057]  eta: 0:01:48  lr: 0.000500  loss: 0.2026 (0.1906)  loss_classifier: 0.0811 (0.0773)  loss_box_reg: 0.0967 (0.0945)  loss_objectness: 0.0035 (0.0057)  loss_rpn_box_reg: 0.0087 (0.0131)  time: 0.6975  data: 0.0002  max mem: 10941\n",
            "Epoch: [3]  [4000/4057]  eta: 0:00:39  lr: 0.000500  loss: 0.2091 (0.1910)  loss_classifier: 0.0850 (0.0774)  loss_box_reg: 0.1029 (0.0948)  loss_objectness: 0.0040 (0.0057)  loss_rpn_box_reg: 0.0078 (0.0132)  time: 0.6825  data: 0.0006  max mem: 10941\n",
            "Epoch: [3]  [4056/4057]  eta: 0:00:00  lr: 0.000500  loss: 0.2074 (0.1910)  loss_classifier: 0.0805 (0.0774)  loss_box_reg: 0.0989 (0.0947)  loss_objectness: 0.0029 (0.0057)  loss_rpn_box_reg: 0.0107 (0.0132)  time: 0.6733  data: 0.0004  max mem: 10941\n",
            "Epoch: [3] Total time: 0:46:31 (0.6882 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:24  model_time: 0.2845 (0.2845)  evaluator_time: 0.0121 (0.0121)  time: 0.6442  data: 0.3447  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2868 (0.2892)  evaluator_time: 0.0085 (0.0086)  time: 0.2925  data: 0.0001  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2935 (0.2895)  evaluator_time: 0.0091 (0.0085)  time: 0.3085  data: 0.0003  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2900 (0.2887)  evaluator_time: 0.0085 (0.0087)  time: 0.2933  data: 0.0004  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.3011 s / it)\n",
            "Averaged stats: model_time: 0.2900 (0.2887)  evaluator_time: 0.0085 (0.0087)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.52s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.427\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:31  model_time: 0.2699 (0.2699)  evaluator_time: 0.0150 (0.0150)  time: 0.6720  data: 0.3853  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2888 (0.2891)  evaluator_time: 0.0085 (0.0084)  time: 0.2924  data: 0.0002  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2923 (0.2876)  evaluator_time: 0.0086 (0.0084)  time: 0.3081  data: 0.0007  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2890 (0.2870)  evaluator_time: 0.0090 (0.0087)  time: 0.2939  data: 0.0005  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.2998 s / it)\n",
            "Averaged stats: model_time: 0.2890 (0.2870)  evaluator_time: 0.0090 (0.0087)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.61s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.552\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.427\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.627\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n",
            "Epoch: [4]  [   0/4057]  eta: 1:16:31  lr: 0.000500  loss: 0.1523 (0.1523)  loss_classifier: 0.0511 (0.0511)  loss_box_reg: 0.0896 (0.0896)  loss_objectness: 0.0011 (0.0011)  loss_rpn_box_reg: 0.0105 (0.0105)  time: 1.1317  data: 0.3617  max mem: 10941\n",
            "Epoch: [4]  [ 100/4057]  eta: 0:46:40  lr: 0.000500  loss: 0.1139 (0.1753)  loss_classifier: 0.0384 (0.0684)  loss_box_reg: 0.0636 (0.0899)  loss_objectness: 0.0016 (0.0045)  loss_rpn_box_reg: 0.0077 (0.0124)  time: 0.7293  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [ 200/4057]  eta: 0:44:22  lr: 0.000500  loss: 0.1369 (0.1688)  loss_classifier: 0.0580 (0.0663)  loss_box_reg: 0.0656 (0.0855)  loss_objectness: 0.0036 (0.0052)  loss_rpn_box_reg: 0.0076 (0.0117)  time: 0.6562  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [ 300/4057]  eta: 0:43:08  lr: 0.000500  loss: 0.1677 (0.1728)  loss_classifier: 0.0686 (0.0676)  loss_box_reg: 0.0888 (0.0876)  loss_objectness: 0.0052 (0.0054)  loss_rpn_box_reg: 0.0104 (0.0122)  time: 0.6599  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [ 400/4057]  eta: 0:41:54  lr: 0.000500  loss: 0.1391 (0.1713)  loss_classifier: 0.0568 (0.0676)  loss_box_reg: 0.0732 (0.0861)  loss_objectness: 0.0031 (0.0053)  loss_rpn_box_reg: 0.0091 (0.0122)  time: 0.6960  data: 0.0006  max mem: 10941\n",
            "Epoch: [4]  [ 500/4057]  eta: 0:40:33  lr: 0.000500  loss: 0.1677 (0.1745)  loss_classifier: 0.0704 (0.0688)  loss_box_reg: 0.0852 (0.0879)  loss_objectness: 0.0057 (0.0053)  loss_rpn_box_reg: 0.0127 (0.0125)  time: 0.6501  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [ 600/4057]  eta: 0:39:28  lr: 0.000500  loss: 0.1548 (0.1749)  loss_classifier: 0.0703 (0.0690)  loss_box_reg: 0.1017 (0.0885)  loss_objectness: 0.0030 (0.0051)  loss_rpn_box_reg: 0.0079 (0.0123)  time: 0.6768  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [ 700/4057]  eta: 0:38:22  lr: 0.000500  loss: 0.1584 (0.1780)  loss_classifier: 0.0570 (0.0703)  loss_box_reg: 0.0827 (0.0898)  loss_objectness: 0.0037 (0.0052)  loss_rpn_box_reg: 0.0083 (0.0126)  time: 0.6961  data: 0.0003  max mem: 10941\n",
            "Epoch: [4]  [ 800/4057]  eta: 0:37:22  lr: 0.000500  loss: 0.1978 (0.1780)  loss_classifier: 0.0709 (0.0703)  loss_box_reg: 0.0807 (0.0898)  loss_objectness: 0.0030 (0.0052)  loss_rpn_box_reg: 0.0089 (0.0127)  time: 0.7229  data: 0.0004  max mem: 10941\n",
            "Epoch: [4]  [ 900/4057]  eta: 0:36:09  lr: 0.000500  loss: 0.1649 (0.1773)  loss_classifier: 0.0627 (0.0698)  loss_box_reg: 0.0860 (0.0897)  loss_objectness: 0.0033 (0.0051)  loss_rpn_box_reg: 0.0122 (0.0127)  time: 0.6745  data: 0.0006  max mem: 10941\n",
            "Epoch: [4]  [1000/4057]  eta: 0:35:00  lr: 0.000500  loss: 0.1180 (0.1765)  loss_classifier: 0.0430 (0.0695)  loss_box_reg: 0.0608 (0.0892)  loss_objectness: 0.0030 (0.0051)  loss_rpn_box_reg: 0.0081 (0.0127)  time: 0.6745  data: 0.0006  max mem: 10941\n",
            "Epoch: [4]  [1100/4057]  eta: 0:34:00  lr: 0.000500  loss: 0.1522 (0.1769)  loss_classifier: 0.0660 (0.0698)  loss_box_reg: 0.0669 (0.0893)  loss_objectness: 0.0032 (0.0051)  loss_rpn_box_reg: 0.0145 (0.0127)  time: 0.7337  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [1200/4057]  eta: 0:32:52  lr: 0.000500  loss: 0.1336 (0.1771)  loss_classifier: 0.0582 (0.0700)  loss_box_reg: 0.0688 (0.0894)  loss_objectness: 0.0036 (0.0050)  loss_rpn_box_reg: 0.0066 (0.0127)  time: 0.7049  data: 0.0003  max mem: 10941\n",
            "Epoch: [4]  [1300/4057]  eta: 0:31:43  lr: 0.000500  loss: 0.1717 (0.1773)  loss_classifier: 0.0652 (0.0699)  loss_box_reg: 0.0674 (0.0897)  loss_objectness: 0.0045 (0.0050)  loss_rpn_box_reg: 0.0110 (0.0127)  time: 0.6993  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [1400/4057]  eta: 0:30:33  lr: 0.000500  loss: 0.1822 (0.1774)  loss_classifier: 0.0700 (0.0702)  loss_box_reg: 0.0943 (0.0895)  loss_objectness: 0.0031 (0.0050)  loss_rpn_box_reg: 0.0091 (0.0127)  time: 0.7114  data: 0.0005  max mem: 10941\n",
            "Epoch: [4]  [1500/4057]  eta: 0:29:24  lr: 0.000500  loss: 0.1338 (0.1767)  loss_classifier: 0.0558 (0.0700)  loss_box_reg: 0.0606 (0.0890)  loss_objectness: 0.0033 (0.0049)  loss_rpn_box_reg: 0.0100 (0.0127)  time: 0.7005  data: 0.0004  max mem: 10941\n",
            "Epoch: [4]  [1600/4057]  eta: 0:28:14  lr: 0.000500  loss: 0.1447 (0.1776)  loss_classifier: 0.0589 (0.0703)  loss_box_reg: 0.0766 (0.0895)  loss_objectness: 0.0030 (0.0050)  loss_rpn_box_reg: 0.0094 (0.0128)  time: 0.6928  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [1700/4057]  eta: 0:27:03  lr: 0.000500  loss: 0.1627 (0.1781)  loss_classifier: 0.0572 (0.0705)  loss_box_reg: 0.0879 (0.0898)  loss_objectness: 0.0048 (0.0050)  loss_rpn_box_reg: 0.0079 (0.0128)  time: 0.6662  data: 0.0005  max mem: 10941\n",
            "Epoch: [4]  [1800/4057]  eta: 0:25:53  lr: 0.000500  loss: 0.1394 (0.1773)  loss_classifier: 0.0545 (0.0701)  loss_box_reg: 0.0660 (0.0894)  loss_objectness: 0.0021 (0.0049)  loss_rpn_box_reg: 0.0076 (0.0128)  time: 0.6820  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [1900/4057]  eta: 0:24:44  lr: 0.000500  loss: 0.2028 (0.1772)  loss_classifier: 0.0822 (0.0702)  loss_box_reg: 0.1086 (0.0893)  loss_objectness: 0.0057 (0.0049)  loss_rpn_box_reg: 0.0124 (0.0128)  time: 0.6919  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [2000/4057]  eta: 0:23:36  lr: 0.000500  loss: 0.1454 (0.1766)  loss_classifier: 0.0517 (0.0700)  loss_box_reg: 0.0621 (0.0889)  loss_objectness: 0.0038 (0.0049)  loss_rpn_box_reg: 0.0137 (0.0128)  time: 0.7045  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [2100/4057]  eta: 0:22:27  lr: 0.000500  loss: 0.1510 (0.1765)  loss_classifier: 0.0706 (0.0700)  loss_box_reg: 0.0735 (0.0888)  loss_objectness: 0.0021 (0.0049)  loss_rpn_box_reg: 0.0077 (0.0128)  time: 0.7153  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [2200/4057]  eta: 0:21:18  lr: 0.000500  loss: 0.1427 (0.1762)  loss_classifier: 0.0572 (0.0699)  loss_box_reg: 0.0844 (0.0886)  loss_objectness: 0.0023 (0.0049)  loss_rpn_box_reg: 0.0129 (0.0127)  time: 0.7211  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [2300/4057]  eta: 0:20:09  lr: 0.000500  loss: 0.1651 (0.1765)  loss_classifier: 0.0683 (0.0701)  loss_box_reg: 0.0803 (0.0889)  loss_objectness: 0.0043 (0.0048)  loss_rpn_box_reg: 0.0082 (0.0127)  time: 0.6653  data: 0.0003  max mem: 10941\n",
            "Epoch: [4]  [2400/4057]  eta: 0:19:00  lr: 0.000500  loss: 0.1673 (0.1772)  loss_classifier: 0.0728 (0.0704)  loss_box_reg: 0.0783 (0.0891)  loss_objectness: 0.0039 (0.0049)  loss_rpn_box_reg: 0.0116 (0.0128)  time: 0.6974  data: 0.0005  max mem: 10941\n",
            "Epoch: [4]  [2500/4057]  eta: 0:17:51  lr: 0.000500  loss: 0.1536 (0.1773)  loss_classifier: 0.0595 (0.0705)  loss_box_reg: 0.0847 (0.0892)  loss_objectness: 0.0026 (0.0049)  loss_rpn_box_reg: 0.0083 (0.0128)  time: 0.6701  data: 0.0006  max mem: 10941\n",
            "Epoch: [4]  [2600/4057]  eta: 0:16:41  lr: 0.000500  loss: 0.2090 (0.1775)  loss_classifier: 0.0727 (0.0705)  loss_box_reg: 0.1064 (0.0894)  loss_objectness: 0.0049 (0.0049)  loss_rpn_box_reg: 0.0072 (0.0127)  time: 0.6872  data: 0.0003  max mem: 10941\n",
            "Epoch: [4]  [2700/4057]  eta: 0:15:32  lr: 0.000500  loss: 0.1692 (0.1772)  loss_classifier: 0.0639 (0.0704)  loss_box_reg: 0.0908 (0.0893)  loss_objectness: 0.0034 (0.0049)  loss_rpn_box_reg: 0.0093 (0.0127)  time: 0.6608  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [2800/4057]  eta: 0:14:23  lr: 0.000500  loss: 0.1877 (0.1775)  loss_classifier: 0.0628 (0.0704)  loss_box_reg: 0.1015 (0.0895)  loss_objectness: 0.0050 (0.0049)  loss_rpn_box_reg: 0.0132 (0.0128)  time: 0.6648  data: 0.0005  max mem: 10941\n",
            "Epoch: [4]  [2900/4057]  eta: 0:13:15  lr: 0.000500  loss: 0.1278 (0.1770)  loss_classifier: 0.0562 (0.0702)  loss_box_reg: 0.0633 (0.0892)  loss_objectness: 0.0042 (0.0049)  loss_rpn_box_reg: 0.0100 (0.0128)  time: 0.6509  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [3000/4057]  eta: 0:12:06  lr: 0.000500  loss: 0.1675 (0.1768)  loss_classifier: 0.0645 (0.0702)  loss_box_reg: 0.0823 (0.0891)  loss_objectness: 0.0031 (0.0048)  loss_rpn_box_reg: 0.0104 (0.0128)  time: 0.6749  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [3100/4057]  eta: 0:10:57  lr: 0.000500  loss: 0.1590 (0.1769)  loss_classifier: 0.0635 (0.0703)  loss_box_reg: 0.0809 (0.0890)  loss_objectness: 0.0046 (0.0049)  loss_rpn_box_reg: 0.0081 (0.0127)  time: 0.6339  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [3200/4057]  eta: 0:09:48  lr: 0.000500  loss: 0.1415 (0.1771)  loss_classifier: 0.0607 (0.0703)  loss_box_reg: 0.0754 (0.0892)  loss_objectness: 0.0027 (0.0049)  loss_rpn_box_reg: 0.0061 (0.0127)  time: 0.6757  data: 0.0003  max mem: 10941\n",
            "Epoch: [4]  [3300/4057]  eta: 0:08:39  lr: 0.000500  loss: 0.1199 (0.1774)  loss_classifier: 0.0434 (0.0705)  loss_box_reg: 0.0613 (0.0893)  loss_objectness: 0.0028 (0.0049)  loss_rpn_box_reg: 0.0109 (0.0127)  time: 0.7087  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [3400/4057]  eta: 0:07:31  lr: 0.000500  loss: 0.1896 (0.1775)  loss_classifier: 0.0749 (0.0705)  loss_box_reg: 0.0969 (0.0894)  loss_objectness: 0.0023 (0.0049)  loss_rpn_box_reg: 0.0099 (0.0127)  time: 0.6835  data: 0.0003  max mem: 10941\n",
            "Epoch: [4]  [3500/4057]  eta: 0:06:22  lr: 0.000500  loss: 0.1388 (0.1778)  loss_classifier: 0.0601 (0.0707)  loss_box_reg: 0.0776 (0.0895)  loss_objectness: 0.0032 (0.0049)  loss_rpn_box_reg: 0.0076 (0.0127)  time: 0.6927  data: 0.0007  max mem: 10941\n",
            "Epoch: [4]  [3600/4057]  eta: 0:05:13  lr: 0.000500  loss: 0.1750 (0.1777)  loss_classifier: 0.0657 (0.0706)  loss_box_reg: 0.0824 (0.0895)  loss_objectness: 0.0035 (0.0049)  loss_rpn_box_reg: 0.0058 (0.0127)  time: 0.6694  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [3700/4057]  eta: 0:04:05  lr: 0.000500  loss: 0.1245 (0.1781)  loss_classifier: 0.0563 (0.0707)  loss_box_reg: 0.0565 (0.0897)  loss_objectness: 0.0038 (0.0049)  loss_rpn_box_reg: 0.0093 (0.0128)  time: 0.6609  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [3800/4057]  eta: 0:02:56  lr: 0.000500  loss: 0.1691 (0.1782)  loss_classifier: 0.0752 (0.0708)  loss_box_reg: 0.0787 (0.0897)  loss_objectness: 0.0028 (0.0049)  loss_rpn_box_reg: 0.0092 (0.0128)  time: 0.7266  data: 0.0007  max mem: 10941\n",
            "Epoch: [4]  [3900/4057]  eta: 0:01:47  lr: 0.000500  loss: 0.1872 (0.1784)  loss_classifier: 0.0682 (0.0709)  loss_box_reg: 0.1052 (0.0899)  loss_objectness: 0.0047 (0.0049)  loss_rpn_box_reg: 0.0070 (0.0128)  time: 0.6765  data: 0.0007  max mem: 10941\n",
            "Epoch: [4]  [4000/4057]  eta: 0:00:39  lr: 0.000500  loss: 0.1565 (0.1781)  loss_classifier: 0.0542 (0.0708)  loss_box_reg: 0.0920 (0.0898)  loss_objectness: 0.0029 (0.0049)  loss_rpn_box_reg: 0.0069 (0.0127)  time: 0.7036  data: 0.0002  max mem: 10941\n",
            "Epoch: [4]  [4056/4057]  eta: 0:00:00  lr: 0.000500  loss: 0.1501 (0.1781)  loss_classifier: 0.0733 (0.0708)  loss_box_reg: 0.0691 (0.0897)  loss_objectness: 0.0041 (0.0049)  loss_rpn_box_reg: 0.0073 (0.0127)  time: 0.6707  data: 0.0003  max mem: 10941\n",
            "Epoch: [4] Total time: 0:46:28 (0.6873 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:43  model_time: 0.2378 (0.2378)  evaluator_time: 0.0160 (0.0160)  time: 0.7264  data: 0.4711  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2862 (0.2889)  evaluator_time: 0.0078 (0.0078)  time: 0.2924  data: 0.0002  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2903 (0.2878)  evaluator_time: 0.0088 (0.0078)  time: 0.3081  data: 0.0002  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2891 (0.2873)  evaluator_time: 0.0081 (0.0080)  time: 0.2934  data: 0.0002  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.2996 s / it)\n",
            "Averaged stats: model_time: 0.2891 (0.2873)  evaluator_time: 0.0081 (0.0080)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.48s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.557\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:35  model_time: 0.2517 (0.2517)  evaluator_time: 0.0122 (0.0122)  time: 0.6924  data: 0.4271  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2861 (0.2889)  evaluator_time: 0.0072 (0.0078)  time: 0.2916  data: 0.0001  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2905 (0.2880)  evaluator_time: 0.0076 (0.0078)  time: 0.3080  data: 0.0002  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2903 (0.2874)  evaluator_time: 0.0081 (0.0080)  time: 0.2931  data: 0.0003  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.2995 s / it)\n",
            "Averaged stats: model_time: 0.2903 (0.2874)  evaluator_time: 0.0081 (0.0080)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.48s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.557\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n",
            "Epoch: [5]  [   0/4057]  eta: 1:14:24  lr: 0.000500  loss: 0.1028 (0.1028)  loss_classifier: 0.0329 (0.0329)  loss_box_reg: 0.0464 (0.0464)  loss_objectness: 0.0045 (0.0045)  loss_rpn_box_reg: 0.0191 (0.0191)  time: 1.1004  data: 0.3511  max mem: 10941\n",
            "Epoch: [5]  [ 100/4057]  eta: 0:44:15  lr: 0.000500  loss: 0.1187 (0.1666)  loss_classifier: 0.0500 (0.0669)  loss_box_reg: 0.0688 (0.0828)  loss_objectness: 0.0025 (0.0050)  loss_rpn_box_reg: 0.0077 (0.0120)  time: 0.6748  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [ 200/4057]  eta: 0:43:32  lr: 0.000500  loss: 0.1623 (0.1722)  loss_classifier: 0.0651 (0.0692)  loss_box_reg: 0.0880 (0.0859)  loss_objectness: 0.0041 (0.0049)  loss_rpn_box_reg: 0.0098 (0.0121)  time: 0.6702  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [ 300/4057]  eta: 0:42:39  lr: 0.000500  loss: 0.1436 (0.1674)  loss_classifier: 0.0607 (0.0665)  loss_box_reg: 0.0763 (0.0844)  loss_objectness: 0.0036 (0.0045)  loss_rpn_box_reg: 0.0082 (0.0119)  time: 0.6576  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [ 400/4057]  eta: 0:41:35  lr: 0.000500  loss: 0.1164 (0.1664)  loss_classifier: 0.0461 (0.0662)  loss_box_reg: 0.0505 (0.0838)  loss_objectness: 0.0037 (0.0045)  loss_rpn_box_reg: 0.0075 (0.0119)  time: 0.6912  data: 0.0005  max mem: 10941\n",
            "Epoch: [5]  [ 500/4057]  eta: 0:40:41  lr: 0.000500  loss: 0.1609 (0.1663)  loss_classifier: 0.0540 (0.0658)  loss_box_reg: 0.0843 (0.0842)  loss_objectness: 0.0031 (0.0043)  loss_rpn_box_reg: 0.0069 (0.0119)  time: 0.7128  data: 0.0005  max mem: 10941\n",
            "Epoch: [5]  [ 600/4057]  eta: 0:39:38  lr: 0.000500  loss: 0.1875 (0.1679)  loss_classifier: 0.0553 (0.0664)  loss_box_reg: 0.1022 (0.0848)  loss_objectness: 0.0038 (0.0045)  loss_rpn_box_reg: 0.0105 (0.0122)  time: 0.6631  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [ 700/4057]  eta: 0:38:34  lr: 0.000500  loss: 0.1482 (0.1686)  loss_classifier: 0.0574 (0.0666)  loss_box_reg: 0.0600 (0.0852)  loss_objectness: 0.0032 (0.0045)  loss_rpn_box_reg: 0.0128 (0.0123)  time: 0.7049  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [ 800/4057]  eta: 0:37:25  lr: 0.000500  loss: 0.1185 (0.1689)  loss_classifier: 0.0600 (0.0669)  loss_box_reg: 0.0642 (0.0851)  loss_objectness: 0.0027 (0.0045)  loss_rpn_box_reg: 0.0122 (0.0124)  time: 0.7126  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [ 900/4057]  eta: 0:36:13  lr: 0.000500  loss: 0.1681 (0.1698)  loss_classifier: 0.0724 (0.0673)  loss_box_reg: 0.0892 (0.0856)  loss_objectness: 0.0024 (0.0045)  loss_rpn_box_reg: 0.0087 (0.0124)  time: 0.6755  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [1000/4057]  eta: 0:35:01  lr: 0.000500  loss: 0.1788 (0.1699)  loss_classifier: 0.0661 (0.0674)  loss_box_reg: 0.0990 (0.0856)  loss_objectness: 0.0046 (0.0045)  loss_rpn_box_reg: 0.0107 (0.0124)  time: 0.6616  data: 0.0005  max mem: 10941\n",
            "Epoch: [5]  [1100/4057]  eta: 0:33:55  lr: 0.000500  loss: 0.1563 (0.1698)  loss_classifier: 0.0464 (0.0672)  loss_box_reg: 0.0908 (0.0858)  loss_objectness: 0.0031 (0.0044)  loss_rpn_box_reg: 0.0090 (0.0125)  time: 0.6627  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [1200/4057]  eta: 0:32:44  lr: 0.000500  loss: 0.1349 (0.1709)  loss_classifier: 0.0475 (0.0675)  loss_box_reg: 0.0594 (0.0863)  loss_objectness: 0.0040 (0.0045)  loss_rpn_box_reg: 0.0128 (0.0126)  time: 0.6847  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [1300/4057]  eta: 0:31:36  lr: 0.000500  loss: 0.1753 (0.1715)  loss_classifier: 0.0636 (0.0675)  loss_box_reg: 0.0959 (0.0869)  loss_objectness: 0.0026 (0.0045)  loss_rpn_box_reg: 0.0089 (0.0126)  time: 0.7162  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [1400/4057]  eta: 0:30:28  lr: 0.000500  loss: 0.1563 (0.1710)  loss_classifier: 0.0592 (0.0674)  loss_box_reg: 0.0768 (0.0865)  loss_objectness: 0.0034 (0.0045)  loss_rpn_box_reg: 0.0086 (0.0126)  time: 0.6964  data: 0.0006  max mem: 10941\n",
            "Epoch: [5]  [1500/4057]  eta: 0:29:17  lr: 0.000500  loss: 0.1800 (0.1718)  loss_classifier: 0.0643 (0.0679)  loss_box_reg: 0.0849 (0.0868)  loss_objectness: 0.0026 (0.0045)  loss_rpn_box_reg: 0.0063 (0.0126)  time: 0.7035  data: 0.0006  max mem: 10941\n",
            "Epoch: [5]  [1600/4057]  eta: 0:28:08  lr: 0.000500  loss: 0.1395 (0.1706)  loss_classifier: 0.0642 (0.0675)  loss_box_reg: 0.0737 (0.0863)  loss_objectness: 0.0034 (0.0045)  loss_rpn_box_reg: 0.0097 (0.0124)  time: 0.6730  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [1700/4057]  eta: 0:27:01  lr: 0.000500  loss: 0.1527 (0.1713)  loss_classifier: 0.0552 (0.0676)  loss_box_reg: 0.0840 (0.0868)  loss_objectness: 0.0044 (0.0045)  loss_rpn_box_reg: 0.0126 (0.0125)  time: 0.6602  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [1800/4057]  eta: 0:25:52  lr: 0.000500  loss: 0.1267 (0.1715)  loss_classifier: 0.0550 (0.0677)  loss_box_reg: 0.0586 (0.0870)  loss_objectness: 0.0022 (0.0044)  loss_rpn_box_reg: 0.0139 (0.0125)  time: 0.7329  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [1900/4057]  eta: 0:24:43  lr: 0.000500  loss: 0.1584 (0.1718)  loss_classifier: 0.0614 (0.0677)  loss_box_reg: 0.0646 (0.0871)  loss_objectness: 0.0026 (0.0044)  loss_rpn_box_reg: 0.0109 (0.0125)  time: 0.6696  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [2000/4057]  eta: 0:23:34  lr: 0.000500  loss: 0.1445 (0.1717)  loss_classifier: 0.0572 (0.0676)  loss_box_reg: 0.0668 (0.0871)  loss_objectness: 0.0035 (0.0045)  loss_rpn_box_reg: 0.0105 (0.0125)  time: 0.6889  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [2100/4057]  eta: 0:22:23  lr: 0.000500  loss: 0.1448 (0.1717)  loss_classifier: 0.0588 (0.0676)  loss_box_reg: 0.0754 (0.0871)  loss_objectness: 0.0019 (0.0045)  loss_rpn_box_reg: 0.0076 (0.0125)  time: 0.6678  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [2200/4057]  eta: 0:21:14  lr: 0.000500  loss: 0.1507 (0.1718)  loss_classifier: 0.0621 (0.0677)  loss_box_reg: 0.0827 (0.0871)  loss_objectness: 0.0031 (0.0045)  loss_rpn_box_reg: 0.0093 (0.0125)  time: 0.6948  data: 0.0005  max mem: 10941\n",
            "Epoch: [5]  [2300/4057]  eta: 0:20:06  lr: 0.000500  loss: 0.1444 (0.1719)  loss_classifier: 0.0557 (0.0677)  loss_box_reg: 0.0799 (0.0872)  loss_objectness: 0.0030 (0.0045)  loss_rpn_box_reg: 0.0108 (0.0125)  time: 0.7091  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [2400/4057]  eta: 0:18:58  lr: 0.000500  loss: 0.1423 (0.1721)  loss_classifier: 0.0571 (0.0678)  loss_box_reg: 0.0641 (0.0872)  loss_objectness: 0.0021 (0.0045)  loss_rpn_box_reg: 0.0078 (0.0126)  time: 0.6964  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [2500/4057]  eta: 0:17:49  lr: 0.000500  loss: 0.1621 (0.1720)  loss_classifier: 0.0611 (0.0678)  loss_box_reg: 0.0829 (0.0872)  loss_objectness: 0.0024 (0.0045)  loss_rpn_box_reg: 0.0098 (0.0125)  time: 0.7052  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [2600/4057]  eta: 0:16:39  lr: 0.000500  loss: 0.1313 (0.1724)  loss_classifier: 0.0573 (0.0680)  loss_box_reg: 0.0658 (0.0874)  loss_objectness: 0.0025 (0.0045)  loss_rpn_box_reg: 0.0112 (0.0125)  time: 0.6805  data: 0.0004  max mem: 10941\n",
            "Epoch: [5]  [2700/4057]  eta: 0:15:30  lr: 0.000500  loss: 0.1556 (0.1724)  loss_classifier: 0.0700 (0.0681)  loss_box_reg: 0.0785 (0.0873)  loss_objectness: 0.0026 (0.0045)  loss_rpn_box_reg: 0.0073 (0.0125)  time: 0.7121  data: 0.0004  max mem: 10941\n",
            "Epoch: [5]  [2800/4057]  eta: 0:14:22  lr: 0.000500  loss: 0.1410 (0.1726)  loss_classifier: 0.0642 (0.0681)  loss_box_reg: 0.0708 (0.0875)  loss_objectness: 0.0030 (0.0045)  loss_rpn_box_reg: 0.0075 (0.0125)  time: 0.7241  data: 0.0008  max mem: 10941\n",
            "Epoch: [5]  [2900/4057]  eta: 0:13:14  lr: 0.000500  loss: 0.1385 (0.1722)  loss_classifier: 0.0648 (0.0679)  loss_box_reg: 0.0593 (0.0873)  loss_objectness: 0.0019 (0.0045)  loss_rpn_box_reg: 0.0085 (0.0125)  time: 0.6810  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [3000/4057]  eta: 0:12:05  lr: 0.000500  loss: 0.1421 (0.1724)  loss_classifier: 0.0639 (0.0681)  loss_box_reg: 0.0779 (0.0874)  loss_objectness: 0.0043 (0.0045)  loss_rpn_box_reg: 0.0060 (0.0125)  time: 0.7073  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [3100/4057]  eta: 0:10:57  lr: 0.000500  loss: 0.1493 (0.1723)  loss_classifier: 0.0593 (0.0680)  loss_box_reg: 0.0667 (0.0872)  loss_objectness: 0.0026 (0.0045)  loss_rpn_box_reg: 0.0097 (0.0125)  time: 0.7057  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [3200/4057]  eta: 0:09:49  lr: 0.000500  loss: 0.1591 (0.1724)  loss_classifier: 0.0557 (0.0681)  loss_box_reg: 0.0859 (0.0873)  loss_objectness: 0.0037 (0.0045)  loss_rpn_box_reg: 0.0080 (0.0125)  time: 0.6834  data: 0.0006  max mem: 10941\n",
            "Epoch: [5]  [3300/4057]  eta: 0:08:40  lr: 0.000500  loss: 0.1618 (0.1721)  loss_classifier: 0.0567 (0.0680)  loss_box_reg: 0.0784 (0.0871)  loss_objectness: 0.0033 (0.0045)  loss_rpn_box_reg: 0.0085 (0.0126)  time: 0.7086  data: 0.0002  max mem: 10941\n",
            "Epoch: [5]  [3400/4057]  eta: 0:07:32  lr: 0.000500  loss: 0.1269 (0.1720)  loss_classifier: 0.0470 (0.0679)  loss_box_reg: 0.0636 (0.0871)  loss_objectness: 0.0023 (0.0045)  loss_rpn_box_reg: 0.0125 (0.0126)  time: 0.7193  data: 0.0004  max mem: 10941\n",
            "Epoch: [5]  [3500/4057]  eta: 0:06:23  lr: 0.000500  loss: 0.1231 (0.1718)  loss_classifier: 0.0423 (0.0678)  loss_box_reg: 0.0718 (0.0870)  loss_objectness: 0.0025 (0.0045)  loss_rpn_box_reg: 0.0057 (0.0126)  time: 0.6990  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [3600/4057]  eta: 0:05:14  lr: 0.000500  loss: 0.1428 (0.1715)  loss_classifier: 0.0461 (0.0676)  loss_box_reg: 0.0670 (0.0868)  loss_objectness: 0.0032 (0.0045)  loss_rpn_box_reg: 0.0149 (0.0126)  time: 0.6571  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [3700/4057]  eta: 0:04:05  lr: 0.000500  loss: 0.1435 (0.1716)  loss_classifier: 0.0606 (0.0677)  loss_box_reg: 0.0626 (0.0868)  loss_objectness: 0.0029 (0.0045)  loss_rpn_box_reg: 0.0086 (0.0126)  time: 0.6390  data: 0.0004  max mem: 10941\n",
            "Epoch: [5]  [3800/4057]  eta: 0:02:56  lr: 0.000500  loss: 0.1447 (0.1713)  loss_classifier: 0.0607 (0.0676)  loss_box_reg: 0.0808 (0.0866)  loss_objectness: 0.0030 (0.0045)  loss_rpn_box_reg: 0.0101 (0.0126)  time: 0.6931  data: 0.0003  max mem: 10941\n",
            "Epoch: [5]  [3900/4057]  eta: 0:01:48  lr: 0.000500  loss: 0.1774 (0.1715)  loss_classifier: 0.0586 (0.0677)  loss_box_reg: 0.0702 (0.0868)  loss_objectness: 0.0037 (0.0045)  loss_rpn_box_reg: 0.0112 (0.0126)  time: 0.7066  data: 0.0005  max mem: 10941\n",
            "Epoch: [5]  [4000/4057]  eta: 0:00:39  lr: 0.000500  loss: 0.1417 (0.1713)  loss_classifier: 0.0435 (0.0676)  loss_box_reg: 0.0744 (0.0867)  loss_objectness: 0.0025 (0.0045)  loss_rpn_box_reg: 0.0044 (0.0125)  time: 0.7004  data: 0.0005  max mem: 10941\n",
            "Epoch: [5]  [4056/4057]  eta: 0:00:00  lr: 0.000500  loss: 0.1537 (0.1713)  loss_classifier: 0.0777 (0.0676)  loss_box_reg: 0.0773 (0.0867)  loss_objectness: 0.0048 (0.0045)  loss_rpn_box_reg: 0.0085 (0.0125)  time: 0.7006  data: 0.0003  max mem: 10941\n",
            "Epoch: [5] Total time: 0:46:35 (0.6890 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:30  model_time: 0.2376 (0.2376)  evaluator_time: 0.0110 (0.0110)  time: 0.6693  data: 0.4191  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2895 (0.2889)  evaluator_time: 0.0072 (0.0079)  time: 0.2923  data: 0.0005  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2915 (0.2877)  evaluator_time: 0.0093 (0.0078)  time: 0.3067  data: 0.0002  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2903 (0.2871)  evaluator_time: 0.0081 (0.0080)  time: 0.2923  data: 0.0002  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.2992 s / it)\n",
            "Averaged stats: model_time: 0.2903 (0.2871)  evaluator_time: 0.0081 (0.0080)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.46s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.426\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [  0/225]  eta: 0:02:20  model_time: 0.2734 (0.2734)  evaluator_time: 0.0148 (0.0148)  time: 0.6259  data: 0.3359  max mem: 10941\n",
            "Test:  [100/225]  eta: 0:00:37  model_time: 0.2895 (0.2899)  evaluator_time: 0.0074 (0.0078)  time: 0.2922  data: 0.0002  max mem: 10941\n",
            "Test:  [200/225]  eta: 0:00:07  model_time: 0.2923 (0.2882)  evaluator_time: 0.0083 (0.0078)  time: 0.3072  data: 0.0002  max mem: 10941\n",
            "Test:  [224/225]  eta: 0:00:00  model_time: 0.2891 (0.2876)  evaluator_time: 0.0082 (0.0079)  time: 0.2926  data: 0.0007  max mem: 10941\n",
            "Test: Total time: 0:01:07 (0.2993 s / it)\n",
            "Averaged stats: model_time: 0.2891 (0.2876)  evaluator_time: 0.0082 (0.0079)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.56s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.426\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n",
            "Epoch: [6]  [   0/4057]  eta: 1:23:24  lr: 0.000050  loss: 0.1798 (0.1798)  loss_classifier: 0.0737 (0.0737)  loss_box_reg: 0.0977 (0.0977)  loss_objectness: 0.0024 (0.0024)  loss_rpn_box_reg: 0.0060 (0.0060)  time: 1.2334  data: 0.4821  max mem: 10941\n",
            "Epoch: [6]  [ 100/4057]  eta: 0:46:04  lr: 0.000050  loss: 0.1404 (0.1762)  loss_classifier: 0.0545 (0.0684)  loss_box_reg: 0.0713 (0.0903)  loss_objectness: 0.0035 (0.0053)  loss_rpn_box_reg: 0.0057 (0.0122)  time: 0.6707  data: 0.0002  max mem: 10941\n",
            "Epoch: [6]  [ 200/4057]  eta: 0:44:20  lr: 0.000050  loss: 0.1417 (0.1680)  loss_classifier: 0.0561 (0.0652)  loss_box_reg: 0.0751 (0.0857)  loss_objectness: 0.0021 (0.0047)  loss_rpn_box_reg: 0.0086 (0.0125)  time: 0.6681  data: 0.0002  max mem: 10941\n",
            "Epoch: [6]  [ 300/4057]  eta: 0:42:42  lr: 0.000050  loss: 0.1146 (0.1679)  loss_classifier: 0.0419 (0.0660)  loss_box_reg: 0.0587 (0.0850)  loss_objectness: 0.0035 (0.0047)  loss_rpn_box_reg: 0.0071 (0.0122)  time: 0.6674  data: 0.0004  max mem: 10941\n",
            "Epoch: [6]  [ 400/4057]  eta: 0:41:23  lr: 0.000050  loss: 0.1366 (0.1682)  loss_classifier: 0.0494 (0.0660)  loss_box_reg: 0.0771 (0.0854)  loss_objectness: 0.0025 (0.0045)  loss_rpn_box_reg: 0.0112 (0.0122)  time: 0.7164  data: 0.0003  max mem: 10941\n",
            "Epoch: [6]  [ 500/4057]  eta: 0:40:21  lr: 0.000050  loss: 0.1144 (0.1627)  loss_classifier: 0.0470 (0.0641)  loss_box_reg: 0.0473 (0.0823)  loss_objectness: 0.0020 (0.0044)  loss_rpn_box_reg: 0.0061 (0.0120)  time: 0.7152  data: 0.0003  max mem: 10941\n",
            "Epoch: [6]  [ 600/4057]  eta: 0:39:13  lr: 0.000050  loss: 0.1276 (0.1625)  loss_classifier: 0.0545 (0.0640)  loss_box_reg: 0.0666 (0.0822)  loss_objectness: 0.0026 (0.0044)  loss_rpn_box_reg: 0.0075 (0.0119)  time: 0.6730  data: 0.0002  max mem: 10941\n",
            "Epoch: [6]  [ 700/4057]  eta: 0:38:20  lr: 0.000050  loss: 0.1140 (0.1621)  loss_classifier: 0.0424 (0.0633)  loss_box_reg: 0.0586 (0.0824)  loss_objectness: 0.0029 (0.0043)  loss_rpn_box_reg: 0.0104 (0.0122)  time: 0.7260  data: 0.0002  max mem: 10941\n",
            "Epoch: [6]  [ 800/4057]  eta: 0:37:10  lr: 0.000050  loss: 0.1814 (0.1633)  loss_classifier: 0.0694 (0.0637)  loss_box_reg: 0.0947 (0.0829)  loss_objectness: 0.0042 (0.0043)  loss_rpn_box_reg: 0.0096 (0.0123)  time: 0.6574  data: 0.0002  max mem: 10941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save state dict (just in case)\n",
        "# save_path = os.path.join(\"/content/gdrive/MyDrive/VL&R Project/pascal-training/saved_models\", f\"faster-rcnn-statedict_epochs{epochs}.pt\")\n",
        "# torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "POk4k5t_N16U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to load model again\n",
        "model = torch.load(save_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Psz3WiyrFT_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}